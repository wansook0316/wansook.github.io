<!DOCTYPE html>
<head>
   <!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true,
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
</script>
<script
  type="text/javascript"
  async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
></script> -->

<head>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } });
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["$$","$$"] ],
        processEscapes: true
      }
    });
  </script>
  <script
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
    type="text/javascript"
  ></script>
</head>
 
</head>
<html class="no-js">
  <head>
  <meta charset="utf-8" />
  <title>
    [Kaggle::Titanic] 10: Ensemble | ì™„ìˆ™ì˜ ì—ê·¸ë¨¸ë‹ˆ ğŸ³
  </title>
  <meta
    name="description"
    content="Kaggleì— ìˆëŠ” Titanic Prediction ë¬¸ì œì˜ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. | ëšœë ·í•œ ëª©í‘œ, ì¹˜ë°€í•œ ê³„íš, ìš°ì§í•œ ì‹¤ì²œ"
  />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <!-- Open Graph -->
  <!--  -->
  <meta
    property="og:title"
    content="Kaggleì— ìˆëŠ” Titanic Prediction ë¬¸ì œì˜ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. | ëšœë ·í•œ ëª©í‘œ, ì¹˜ë°€í•œ ê³„íš, ìš°ì§í•œ ì‹¤ì²œ"
  />
  <meta
    property="og:description"
    content="Kaggleì— ìˆëŠ” Titanic Prediction ë¬¸ì œì˜ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. "
  />
  <meta property="og:type" content="website" />
  <meta
    property="og:url"
    content="http://localhost:4000/ds/ml/2020/05/05/titanic-10-Ensemble.html"
  />
  <meta
    property="og:image"
    content="http://localhost:4000/assets/img/36.jpg"
  />

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!--Favicon-->
  <link
    rel="shortcut icon"
    href="/assets/favicon.ico"
    type="image/x-icon"
  />

  <!-- Canonical -->
  <link
    rel="canonical"
    href="/ds/ml/2020/05/05/titanic-10-Ensemble.html"
  />

  <!-- RSS -->
  <link rel="alternate" type="application/atom+xml" title="ì™„ìˆ™ì˜ ì—ê·¸ë¨¸ë‹ˆ ğŸ³" href="/feed.xml" />

  <!-- Font Awesome -->
  <link
    rel="stylesheet"
    href="https://use.fontawesome.com/releases/v5.8.2/css/all.css"
    integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay"
    crossorigin="anonymous"
  />

  <!-- Google Fonts -->
  
  <link
    href="//fonts.googleapis.com/css?family=Nanum+Gothic|Jua|Nanum+Gothic+Coding|Source+Code+Pro|Nanum+Myeongjo:400,700,800|Noto+Sans+KR:100,300,400,500,700,900|monospace"
    rel="stylesheet"
    type="text/css"
  />
  

  <!-- naver web mater tool -->
  <meta
    name="naver-site-verification"
    content="da86adfc2aa8cdd5f1d573b50497f3e29de44cd5"
  />

  <!-- KaTeX -->
  <!--
	
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
		integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

	<script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
		integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ"
		crossorigin="anonymous"></script>
	

    -->
  <!-- Google Analytics -->
  
  <script>
    (function (i, s, o, g, r, a, m) {
      i["GoogleAnalyticsObject"] = r;
      (i[r] =
        i[r] ||
        function () {
          (i[r].q = i[r].q || []).push(arguments);
        }),
        (i[r].l = 1 * new Date());
      (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m);
    })(
      window,
      document,
      "script",
      "//www.google-analytics.com/analytics.js",
      "ga"
    );

    ga("create", "UA-156961472-1", "auto");
    ga("send", "pageview");
  </script>
  

  <!-- Latex -->
  <!--
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
-->

   <!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true,
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
</script>
<script
  type="text/javascript"
  async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
></script> -->

<head>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } });
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["$$","$$"] ],
        processEscapes: true
      }
    });
  </script>
  <script
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
    type="text/javascript"
  ></script>
</head>
  <script>
  console.log(window)

  window.addEventListener("resize", changeContent);
  window.addEventListener("load", changeContent);

  function changeContent(event){
    const width = window.innerWidth;
    console.log(event);
    const cat = document.getElementById("js-cat");
    const cv = document.getElementById("category-cv");
    const book= document.getElementById("category-book");
    const ds = document.getElementById("category-ds");
    const cs = document.getElementById("category-cs");
    const dv = document.getElementById("category-dv");
    const works = document.getElementById("category-works");
    const about = document.getElementById("category-about");
    if (width < 740) {
      cv.innerText = "ğŸ“œ"
      book.innerText = "ğŸ’¡"
      ds.innerText = "ğŸ“ˆ"
      cs.innerText = "ğŸ’¾"
      dv.innerText = "ğŸ“±"
      works.innerText = "ğŸ¨"
      about.innerText = "ğŸ˜"
      cat.style.justifyContent = "space-around"
    } else {
      cv.innerText = "CV"
      book.innerText = "Book"
      ds.innerText = "Data Science"
      cs.innerText = "Computer Science"
      dv.innerText = "Development"
      works.innerText = "Works"
      about.innerText = "About"
      cat.style.justifyContent = "center"
    }

  }
  
</script>
  <script>
  function handleSeriesNavShowing() {
    var side_nav = document.getElementById("js-side_nav");
    var side_nav_button_title = document.getElementById("js-side-btn-content");

    if (side_nav.style.display == "block") {
      side_nav.style.display = "none";
      side_nav_button_title.innerHTML = "â–¼ ëª©ë¡ ë³´ê¸°";
    } else {
      side_nav.style.display = "block";
      side_nav_button_title.innerHTML = "â–² ìˆ¨ê¸°ê¸°";
    }
  }
</script>
  <script>
  function handleTocNavShowing() {
    var toc_nav = document.getElementById("js-toc_nav");
    var toc_nav_button_title = document.getElementById("js-toc-btn-content");

    if (toc_nav.style.display == "block") {
      toc_nav.style.display = "none";
      toc_nav_button_title.innerHTML = "â–¼ ë‚´ë¦¬ê¸°";
    } else {
      toc_nav.style.display = "block";
      toc_nav_button_title.innerHTML = "â–² ìˆ¨ê¸°ê¸°";
    }
  }
</script>

</head>

  <body>
    <header class="site-header">
  <div class="site-title-nav">
    <div class="branding">
      
      <a href="/">
        <img
          class="avatar"
          src="/assets/img/avatar.png"
          alt=""
        />
      </a>
      
      <h1 class="site-title">
        <a href="/">ì™„ìˆ™ì˜ ì—ê·¸ë¨¸ë‹ˆ ğŸ³</a>
      </h1>
    </div>
  </div>
  <nav class="site-nav">
    <ul>
      <!--
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                <li>
                    <a class="page-link" href="/about/">
                        About Me
                    </a>
                </li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
-->
      <!-- Social icons from Font Awesome, if enabled  -->
      <!--                


<li>
	<a href="mailto:wansook0316@gmail.com" title="Email">
		<i class="fas fa-fw fa-envelope"></i>
	</a>
</li>













<li>
	<a href="https://github.com/wansook0316" title="Follow on GitHub">
		<i class="fab fa-fw fa-github"></i>
	</a>
</li>





























-->

      <!-- Search bar -->
      <li>


<li>
	<a href="mailto:wansook0316@gmail.com" title="Email">
		<i class="fas fa-fw fa-envelope"></i>
	</a>
</li>













<li>
	<a href="https://github.com/wansook0316" title="Follow on GitHub">
		<i class="fab fa-fw fa-github"></i>
	</a>
</li>





























</li>
      
      <li>
        <form action="/search.html" method="get">
          <input
            type="text"
            id="search-box"
            name="query"
            placeholder="Search"
            class=""
          />
          <button type="submit" class="">
            <i class="fa fa-fw fa-search"></i>
          </button>
        </form>
      </li>
      
    </ul>
  </nav>
</header>

<div class="site-category">
  <ul class="cat1" id="js-cat">
    <li>
      <a id="category-cv" href="/"> </a>
      <ul>
        <li><a href="/CV/Projects">Projects</a></li>
        <li><a href="/CV/Awards">Awards</a></li>
        <li><a href="/CV/Papers">Papers</a></li>
        <li><a href="/CV/ExtraAct">ExtraCurricular Act</a></li>
        <li><a href="/CV/InternShip">Internship</a></li>
        <li><a href="/CV/Language">Language</a></li>
        <li><a href="/CV/Education">Education</a></li>
        <li><a href="/CV/Qualification">Qualification</a></li>
      </ul>
    </li>

    <li>
      <a id="category-book" href="/"> </a>
      <ul>
        <li><a href="/Book/Finance">Finance</a></li>
        <li><a href="/Book/BM">Business/Marketing</a></li>
        <li><a href="/Book/SM">Self Management</a></li>
        <li><a href="/Book/CH">Culture/History</a></li>
        <li><a href="/Book/Leadership">Leadership</a></li>
        <li><a href="/Book/Classics">Classics</a></li>
        <li><a href="/Book/Think">Think</a></li>
      </ul>
    </li>

    <li>
      <a id="category-ds" href="/"> </a>
      <ul>
        <li><a href="/DS/DL">Deep Learning</a></li>
        <li><a href="/DS/ML">Machine Learning</a></li>
        <li><a href="/DS/Visualization">Visualization</a></li>
        <li><a href="/DS/Statistics">Statistics</a></li>
        <li><a href="/DS/LA">Linear Algebra</a></li>
        <li><a href="/DS/Calculus">Calculus</a></li>
      </ul>
    </li>

    <li>
      <a id="category-cs" href="/"> </a>
      <ul class="category-cs-ul">
        <li class="category-cs-li"><a href="/CS/Network">Network</a></li>
        <li class="category-cs-li"><a href="/CS/Database">Database</a></li>
        <li class="category-cs-li"><a href="/CS/Algorithm">Algorithm</a></li>
        <li class="category-cs-li"><a href="/CS/Structure">Structure</a></li>
        <li class="category-cs-li"><a href="/CS/Parallel">Parallel</a></li>
        <li class="category-cs-li"><a href="/CS/OS">OS</a></li>
      </ul>
    </li>

    <li>
      <a id="category-dv" href="/"> </a>
      <ul class="category-dv-ul">
        <li class="category-dv-li"><a href="/DV/Server">Server</a></li>
        <li class="category-dv-li"><a href="/DV/Linux">Linux</a></li>
        <li class="category-dv-li"><a href="/DV/Python">Python</a></li>
        <li class="category-dv-li"><a href="/DV/C++">C++</a></li>
        <li class="category-dv-li"><a href="/DV/JavaScript">JavaScript</a></li>
        <li class="category-dv-li"><a href="/DV/HTML-CSS">HTML/CSS</a></li>
        <li class="category-dv-li"><a href="/DV/React">React</a></li>
        <li class="category-dv-li"><a href="/DV/Django">Django</a></li>
        <li class="category-dv-li"><a href="/DV/Docker">Docker</a></li>
        <li class="category-dv-li"><a href="/DV/Git">Git</a></li>
        <li class="category-dv-li"><a href="/DV/Tips">Tips</a></li>
        <li class="category-dv-li"><a href="/DV/SP">Side Project</a></li>
      </ul>
    </li>

    <li>
      <a id="category-works" href="/"> </a>
      <ul class="category-works-ul">
        <li class="category-works-li"><a href="/Works/Tags">Tags</a></li>
        <li class="category-works-li"><a href="/Works/Series">Series</a></li>
      </ul>
    </li>

    <li><a id="category-about" href="/about/"> </a></li>

    <!--    <ul class="cat2">-->

    <!--  </ul>-->
  </ul>
</div>

    <div class="content"><article
  class="feature-image main-category-feature"
  
>
  <header
    style="background-image: url('/assets/img/36.jpg')"
  >
    <ul class="category-title">
      <h1 class="title">10: Ensemble</h1>
      
      <p class="meta">
        DS/ML  : Kaggle::Titanic 
      </p>
      <p class="meta">
        May 5, 2020 
      </p>
    </ul>
  </header>

  

  <section class="post-content">
        

<div class="series-nav">
  <p>
    ì´ í¬ìŠ¤íŒ…ì€ <b><em>Kaggle::Titanic</em></b> ì‹œë¦¬ì¦ˆ
    <b><em>10</em></b> í¸ ì¤‘ <b><em>10</em></b> ë²ˆì§¸ ê¸€ ì…ë‹ˆë‹¤.
  </p>
  <ul class="side-nav" id="js-side_nav">
                                               
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-01-%EB%AC%B8%EC%A0%9C%EC%A0%95%EC%9D%98.html'">
      <span>Part 1 - 01: ë¬¸ì œ ì •ì˜</span>
    </li>
                                         
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-02-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%88%98%EC%A7%91.html'">
      <span>Part 2 - 02: ë°ì´í„° ìˆ˜ì§‘</span>
    </li>
                                               
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-03-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EB%A1%9C%EB%93%9C.html'">
      <span>Part 3 - 03: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ</span>
    </li>
                                 
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-04-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%AF%B8%EB%A6%AC%EB%B3%B4%EA%B8%B0.html'">
      <span>Part 4 - 04: ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</span>
    </li>
                           
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-05-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%95%EC%A0%9C.html'">
      <span>Part 5 - 05: ë°ì´í„° ì •ì œ</span>
    </li>
                         
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-06-EDA.html'">
      <span>Part 6 - 06: EDA (Exploratory Data Analysis)</span>
    </li>
                                   
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-07-%EB%AA%A8%EB%8D%B8%EB%A7%81.html'">
      <span>Part 7 - 07: ëª¨ë¸ë§</span>
    </li>
                           
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-08-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80%ED%95%98%EA%B8%B0.html'">
      <span>Part 8 - 08: ëª¨ë¸ë§ í‰ê°€í•˜ê¸°</span>
    </li>
                   
    <li onclick="location.href='/ds/ml/2020/05/05/titanic-09-Hyper-parameter-tuning.html'">
      <span>Part 9 - 09: Hyper Parameter Tuning</span>
    </li>
                   
    <li class="current">
      <span>Part 10 - This Post</span>
    </li>
                                                                                                                                                                                                                                                                                                          
  </ul>
  <div
    class="side-nav-btn"
    id="js-btn-side_nav"
    onclick="handleSeriesNavShowing();"
  >
    <div class="side-nav-btn__content" id="js-side-btn-content">
      â–¼ ëª©ë¡ ë³´ê¸°
    </div>
  </div>
</div>


     

<div class="toc-whole-nav">
  <p>ëª©ì°¨</p>
  <!-- <ul class="toc-nav" id="js-toc_nav"> -->
  <ul id="js-toc_nav" class="toc-nav">
  <li><a href="#ì•™ìƒë¸”">ì•™ìƒë¸”</a>
    <ul>
      <li><a href="#ëª¨ë¸ì˜-ì •í™•ë„ê°„ì˜-ìƒê´€ê³„ìˆ˜">ëª¨ë¸ì˜ ì •í™•ë„ê°„ì˜ ìƒê´€ê³„ìˆ˜</a></li>
      <li><a href="#hard-vote-ë‹¤ìˆ˜ê²°--soft-vote-ê°€ì¤‘ì¹˜">Hard Vote (ë‹¤ìˆ˜ê²°) &amp; Soft Vote (ê°€ì¤‘ì¹˜)</a></li>
      <li><a href="#grid-search">Grid Search</a></li>
      <li><a href="#ì•™ìƒë¸”-1">ì•™ìƒë¸”</a></li>
      <li><a href="#ì‹¤ì œ-validationì—-ì ìš©-for-submit">ì‹¤ì œ validationì— ì ìš© (for submit)</a></li>
    </ul>
  </li>
  <li><a href="#ê²°ë¡ ">ê²°ë¡ </a></li>
</ul>
  <!-- </ul> -->
  <div class="toc-nav-btn" id="js-btn-toc_nav" onclick="handleTocNavShowing();">
    <div class="toc-nav-btn__content" id="js-toc-btn-content">â–¼ ë‚´ë¦¬ê¸°</div>
  </div>
</div>


 <p>Kaggleì— ìˆëŠ” Titanic Prediction ë¬¸ì œì˜ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤.</p>

<h1 id="ì•™ìƒë¸”">ì•™ìƒë¸”</h1>

<blockquote>
  <p>ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ì„ ë§Œë“¤ê³ , ì´ê²ƒë“¤ì˜ ê²°ê³¼ë“¤ì„ íˆ¬í‘œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•©ì¹˜ì.</p>
</blockquote>

<h2 id="ëª¨ë¸ì˜-ì •í™•ë„ê°„ì˜-ìƒê´€ê³„ìˆ˜">ëª¨ë¸ì˜ ì •í™•ë„ê°„ì˜ ìƒê´€ê³„ìˆ˜</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite
#there are some 1's, but enough blues and light reds to create a "super algorithm" by combining them
</span><span class="n">correlation_heatmap</span><span class="p">(</span><span class="n">MLA_predict</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/37871541/81385425-4c315700-914e-11ea-91c4-c8a5f60085ad.png" alt="Unknown-15" class="center" /></p>

<h2 id="hard-vote-ë‹¤ìˆ˜ê²°--soft-vote-ê°€ì¤‘ì¹˜">Hard Vote (ë‹¤ìˆ˜ê²°) &amp; Soft Vote (ê°€ì¤‘ì¹˜)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#why choose one model, when you can pick them all with voting classifier
#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html
#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model
</span><span class="n">vote_est</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1">#Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html
</span>    <span class="p">(</span><span class="s">'ada'</span><span class="p">,</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">AdaBoostClassifier</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'bc'</span><span class="p">,</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">BaggingClassifier</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'etc'</span><span class="p">,</span><span class="n">ensemble</span><span class="o">.</span><span class="n">ExtraTreesClassifier</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'gbc'</span><span class="p">,</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingClassifier</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'rfc'</span><span class="p">,</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">()),</span>

    <span class="c1">#Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc
</span>    <span class="p">(</span><span class="s">'gpc'</span><span class="p">,</span> <span class="n">gaussian_process</span><span class="o">.</span><span class="n">GaussianProcessClassifier</span><span class="p">()),</span>

    <span class="c1">#GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
</span>    <span class="p">(</span><span class="s">'lr'</span><span class="p">,</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegressionCV</span><span class="p">()),</span>

    <span class="c1">#Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html
</span>    <span class="p">(</span><span class="s">'bnb'</span><span class="p">,</span> <span class="n">naive_bayes</span><span class="o">.</span><span class="n">BernoulliNB</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'gnb'</span><span class="p">,</span> <span class="n">naive_bayes</span><span class="o">.</span><span class="n">GaussianNB</span><span class="p">()),</span>

    <span class="c1">#Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html
</span>    <span class="p">(</span><span class="s">'knn'</span><span class="p">,</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">()),</span>

    <span class="c1">#SVM: http://scikit-learn.org/stable/modules/svm.html
</span>    <span class="p">(</span><span class="s">'svc'</span><span class="p">,</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">)),</span>

    <span class="c1">#xgboost: http://xgboost.readthedocs.io/en/latest/model.html
</span>   <span class="p">(</span><span class="s">'xgb'</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">())</span>

<span class="p">]</span>


<span class="c1">#Hard Vote or majority rules, ì´ ë¶€ë¶„ ì½”ë“œê°€ ì•½ê°„ ì´í•´ê°€ ì•ˆë˜ì§€ë§Œ ì¼ë‹¨ ë„˜ì–´ê°„ë‹¤.
</span><span class="n">vote_hard</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span> <span class="o">=</span> <span class="n">vote_est</span> <span class="p">,</span> <span class="n">voting</span> <span class="o">=</span> <span class="s">'hard'</span><span class="p">)</span>
<span class="n">vote_hard_cv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">vote_hard</span><span class="p">,</span> <span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">],</span> <span class="n">cv</span>  <span class="o">=</span> <span class="n">cv_split</span><span class="p">)</span>
<span class="n">vote_hard</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Hard Voting Training w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">vote_hard_cv</span><span class="p">[</span><span class="s">'train_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Hard Voting Test w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">vote_hard_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Hard Voting Test w/bin score 3*std: +/- {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">vote_hard_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>


<span class="c1">#Soft Vote or weighted probabilities
</span><span class="n">vote_soft</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span> <span class="o">=</span> <span class="n">vote_est</span> <span class="p">,</span> <span class="n">voting</span> <span class="o">=</span> <span class="s">'soft'</span><span class="p">)</span>
<span class="n">vote_soft_cv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">vote_soft</span><span class="p">,</span> <span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">],</span> <span class="n">cv</span>  <span class="o">=</span> <span class="n">cv_split</span><span class="p">)</span>
<span class="n">vote_soft</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Soft Voting Training w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">vote_soft_cv</span><span class="p">[</span><span class="s">'train_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Soft Voting Test w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">vote_soft_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Soft Voting Test w/bin score 3*std: +/- {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">vote_soft_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hard Voting Training w/bin score mean: 86.61
Hard Voting Test w/bin score mean: 82.35
Hard Voting Test w/bin score 3*std: +/- 4.91
----------

Soft Voting Training w/bin score mean: 87.21
Soft Voting Test w/bin score mean: 82.43
Soft Voting Test w/bin score 3*std: +/- 5.14
----------
</code></pre></div></div>

<h2 id="grid-search">Grid Search</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#WARNING: Running is very computational intensive and time expensive.
#Code is written for experimental/developmental purposes and not production ready!
</span>

<span class="c1">#Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html
</span><span class="n">grid_n_estimator</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">grid_ratio</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.25</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.75</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">grid_learn</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.03</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.25</span><span class="p">]</span>
<span class="n">grid_max_depth</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span>
<span class="n">grid_min_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">.03</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.10</span><span class="p">]</span>
<span class="n">grid_criterion</span> <span class="o">=</span> <span class="p">[</span><span class="s">'gini'</span><span class="p">,</span> <span class="s">'entropy'</span><span class="p">]</span><span class="err">ã…</span>
<span class="n">grid_bool</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]</span>
<span class="n">grid_seed</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">grid_param</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[{</span>
            <span class="c1">#AdaBoostClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html
</span>            <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">grid_n_estimator</span><span class="p">,</span> <span class="c1">#default=50
</span>            <span class="s">'learning_rate'</span><span class="p">:</span> <span class="n">grid_learn</span><span class="p">,</span> <span class="c1">#default=1
</span>            <span class="c1">#'algorithm': ['SAMME', 'SAMME.R'], #default=â€™SAMME.R
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
            <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#BaggingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier
</span>            <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">grid_n_estimator</span><span class="p">,</span> <span class="c1">#default=10
</span>            <span class="s">'max_samples'</span><span class="p">:</span> <span class="n">grid_ratio</span><span class="p">,</span> <span class="c1">#default=1.0
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#ExtraTreesClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier
</span>            <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">grid_n_estimator</span><span class="p">,</span> <span class="c1">#default=10
</span>            <span class="s">'criterion'</span><span class="p">:</span> <span class="n">grid_criterion</span><span class="p">,</span> <span class="c1">#default=â€giniâ€
</span>            <span class="s">'max_depth'</span><span class="p">:</span> <span class="n">grid_max_depth</span><span class="p">,</span> <span class="c1">#default=None
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#GradientBoostingClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier
</span>            <span class="c1">#'loss': ['deviance', 'exponential'], #default=â€™devianceâ€™
</span>            <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">[</span><span class="mf">.05</span><span class="p">],</span> <span class="c1">#default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.
</span>            <span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">300</span><span class="p">],</span> <span class="c1">#default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.
</span>            <span class="c1">#'criterion': ['friedman_mse', 'mse', 'mae'], #default=â€friedman_mseâ€
</span>            <span class="s">'max_depth'</span><span class="p">:</span> <span class="n">grid_max_depth</span><span class="p">,</span> <span class="c1">#default=3
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier
</span>            <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">grid_n_estimator</span><span class="p">,</span> <span class="c1">#default=10
</span>            <span class="s">'criterion'</span><span class="p">:</span> <span class="n">grid_criterion</span><span class="p">,</span> <span class="c1">#default=â€giniâ€
</span>            <span class="s">'max_depth'</span><span class="p">:</span> <span class="n">grid_max_depth</span><span class="p">,</span> <span class="c1">#default=None
</span>            <span class="s">'oob_score'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">],</span> <span class="c1">#default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}],</span>

            <span class="p">[{</span>
            <span class="c1">#GaussianProcessClassifier
</span>            <span class="s">'max_iter_predict'</span><span class="p">:</span> <span class="n">grid_n_estimator</span><span class="p">,</span> <span class="c1">#default: 100
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
            <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV
</span>            <span class="s">'fit_intercept'</span><span class="p">:</span> <span class="n">grid_bool</span><span class="p">,</span> <span class="c1">#default: True
</span>            <span class="c1">#'penalty': ['l1','l2'],
</span>            <span class="s">'solver'</span><span class="p">:</span> <span class="p">[</span><span class="s">'newton-cg'</span><span class="p">,</span> <span class="s">'lbfgs'</span><span class="p">,</span> <span class="s">'liblinear'</span><span class="p">,</span> <span class="s">'sag'</span><span class="p">,</span> <span class="s">'saga'</span><span class="p">],</span> <span class="c1">#default: lbfgs
</span>            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#BernoulliNB - http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB
</span>            <span class="s">'alpha'</span><span class="p">:</span> <span class="n">grid_ratio</span><span class="p">,</span> <span class="c1">#default: 1.0
</span>             <span class="p">}],</span>


            <span class="c1">#GaussianNB -
</span>            <span class="p">[{}],</span>

            <span class="p">[{</span>
            <span class="c1">#KNeighborsClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier
</span>            <span class="s">'n_neighbors'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">],</span> <span class="c1">#default: 5
</span>            <span class="s">'weights'</span><span class="p">:</span> <span class="p">[</span><span class="s">'uniform'</span><span class="p">,</span> <span class="s">'distance'</span><span class="p">],</span> <span class="c1">#default = â€˜uniformâ€™
</span>            <span class="s">'algorithm'</span><span class="p">:</span> <span class="p">[</span><span class="s">'auto'</span><span class="p">,</span> <span class="s">'ball_tree'</span><span class="p">,</span> <span class="s">'kd_tree'</span><span class="p">,</span> <span class="s">'brute'</span><span class="p">]</span>
            <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#SVC - http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC
</span>            <span class="c1">#http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r
</span>            <span class="c1">#'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
</span>            <span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="c1">#default=1.0
</span>            <span class="s">'gamma'</span><span class="p">:</span> <span class="n">grid_ratio</span><span class="p">,</span> <span class="c1">#edfault: auto
</span>            <span class="s">'decision_function_shape'</span><span class="p">:</span> <span class="p">[</span><span class="s">'ovo'</span><span class="p">,</span> <span class="s">'ovr'</span><span class="p">],</span> <span class="c1">#default:ovr
</span>            <span class="s">'probability'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">],</span>
            <span class="s">'random_state'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}],</span>


            <span class="p">[{</span>
            <span class="c1">#XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html
</span>            <span class="s">'learning_rate'</span><span class="p">:</span> <span class="n">grid_learn</span><span class="p">,</span> <span class="c1">#default: .3
</span>            <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="c1">#default 2
</span>            <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">grid_n_estimator</span><span class="p">,</span>
            <span class="s">'seed'</span><span class="p">:</span> <span class="n">grid_seed</span>
             <span class="p">}]</span>
        <span class="p">]</span>



<span class="n">start_total</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="c1">#https://docs.python.org/3/library/time.html#time.perf_counter
</span><span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span> <span class="p">(</span><span class="n">vote_est</span><span class="p">,</span> <span class="n">grid_param</span><span class="p">):</span> <span class="c1">#https://docs.python.org/3/library/functions.html#zip
</span>
    <span class="c1">#print(clf[1]) #vote_est is a list of tuples, index 0 is the name and index 1 is the algorithm
</span>    <span class="c1">#print(param)
</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">best_search</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">clf</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">cv_split</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">'roc_auc'</span><span class="p">)</span>
    <span class="n">best_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">])</span>
    <span class="n">run</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="n">best_param</span> <span class="o">=</span> <span class="n">best_search</span><span class="o">.</span><span class="n">best_params_</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'The best parameter for {} is {} with a runtime of {:.2f} seconds.'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">clf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span> <span class="n">best_param</span><span class="p">,</span> <span class="n">run</span><span class="p">))</span>
    <span class="n">clf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">best_param</span><span class="p">)</span>


<span class="n">run_total</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_total</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Total optimization time was {:.2f} minutes.'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">run_total</span><span class="o">/</span><span class="mi">60</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">'-'</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The best parameter for AdaBoostClassifier is {'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0} with a runtime of 37.28 seconds.
The best parameter for BaggingClassifier is {'max_samples': 0.25, 'n_estimators': 300, 'random_state': 0} with a runtime of 33.04 seconds.
The best parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0} with a runtime of 68.93 seconds.
The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 38.77 seconds.
The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 84.14 seconds.
The best parameter for GaussianProcessClassifier is {'max_iter_predict': 10, 'random_state': 0} with a runtime of 6.19 seconds.
The best parameter for LogisticRegressionCV is {'fit_intercept': True, 'random_state': 0, 'solver': 'liblinear'} with a runtime of 9.40 seconds.
The best parameter for BernoulliNB is {'alpha': 0.1} with a runtime of 0.24 seconds.
The best parameter for GaussianNB is {} with a runtime of 0.05 seconds.
The best parameter for KNeighborsClassifier is {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'} with a runtime of 5.56 seconds.
The best parameter for SVC is {'C': 2, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'probability': True, 'random_state': 0} with a runtime of 30.49 seconds.
The best parameter for XGBClassifier is {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0} with a runtime of 43.57 seconds.
Total optimization time was 5.96 minutes.
----------
</code></pre></div></div>

<p>voteë¡œ ë“¤ì–´ê°„ ì¶”ì •ê¸° ê°ê°ì— ëŒ€í•´ ìµœì  paramì„ ì°¾ëŠ”ë‹¤.</p>

<h2 id="ì•™ìƒë¸”-1">ì•™ìƒë¸”</h2>

<p>ìµœì ì˜ ì¶”ì •ê¸°ë“¤ì— ëŒ€í•´ ë§ˆì§€ë§‰ìœ¼ë¡œ Votingì„ ìˆ˜í–‰í•œë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Hard Vote or majority rules w/Tuned Hyperparameters
</span><span class="n">grid_hard</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span> <span class="o">=</span> <span class="n">vote_est</span> <span class="p">,</span> <span class="n">voting</span> <span class="o">=</span> <span class="s">'hard'</span><span class="p">)</span>
<span class="n">grid_hard_cv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">grid_hard</span><span class="p">,</span> <span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">],</span> <span class="n">cv</span>  <span class="o">=</span> <span class="n">cv_split</span><span class="p">)</span>
<span class="n">grid_hard</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">grid_hard_cv</span><span class="p">[</span><span class="s">'train_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">grid_hard_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">grid_hard_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>

<span class="c1">#Soft Vote or weighted probabilities w/Tuned Hyperparameters
</span><span class="n">grid_soft</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span> <span class="o">=</span> <span class="n">vote_est</span> <span class="p">,</span> <span class="n">voting</span> <span class="o">=</span> <span class="s">'soft'</span><span class="p">)</span>
<span class="n">grid_soft_cv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">grid_soft</span><span class="p">,</span> <span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">],</span> <span class="n">cv</span>  <span class="o">=</span> <span class="n">cv_split</span><span class="p">)</span>
<span class="n">grid_soft</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">],</span> <span class="n">data1</span><span class="p">[</span><span class="n">Target</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">grid_soft_cv</span><span class="p">[</span><span class="s">'train_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">grid_soft_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}"</span><span class="o">.</span> <span class="nb">format</span><span class="p">(</span><span class="n">grid_soft_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>


<span class="c1">#12/31/17 tuned with data1_x_bin
#The best parameter for AdaBoostClassifier is {'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0} with a runtime of 33.39 seconds.
#The best parameter for BaggingClassifier is {'max_samples': 0.25, 'n_estimators': 300, 'random_state': 0} with a runtime of 30.28 seconds.
#The best parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0} with a runtime of 64.76 seconds.
#The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 34.35 seconds.
#The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 76.32 seconds.
#The best parameter for GaussianProcessClassifier is {'max_iter_predict': 10, 'random_state': 0} with a runtime of 6.01 seconds.
#The best parameter for LogisticRegressionCV is {'fit_intercept': True, 'random_state': 0, 'solver': 'liblinear'} with a runtime of 8.04 seconds.
#The best parameter for BernoulliNB is {'alpha': 0.1} with a runtime of 0.19 seconds.
#The best parameter for GaussianNB is {} with a runtime of 0.04 seconds.
#The best parameter for KNeighborsClassifier is {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'} with a runtime of 4.84 seconds.
#The best parameter for SVC is {'C': 2, 'decision_function_shape': 'ovo', 'gamma': 0.1, 'probability': True, 'random_state': 0} with a runtime of 29.39 seconds.
#The best parameter for XGBClassifier is {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0} with a runtime of 46.23 seconds.
#Total optimization time was 5.56 minutes.
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 85.22
Hard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.31
Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.26
----------
Soft Voting w/Tuned Hyperparameters Training w/bin score mean: 84.76
Soft Voting w/Tuned Hyperparameters Test w/bin score mean: 82.28
Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.42
----------
</code></pre></div></div>

<h2 id="ì‹¤ì œ-validationì—-ì ìš©-for-submit">ì‹¤ì œ validationì— ì ìš© (for submit)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#prepare data for modeling
</span><span class="k">print</span><span class="p">(</span><span class="n">data_val</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-"</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="c1">#data_val.sample(10)
</span>


<span class="c1">#handmade decision tree - submission score = 0.77990
</span><span class="n">data_val</span><span class="p">[</span><span class="s">'Survived'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mytree</span><span class="p">(</span><span class="n">data_val</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>


<span class="c1">#decision tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990
#submit_dt = tree.DecisionTreeClassifier()
#submit_dt = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split)
#submit_dt.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_dt.best_params_) #Best Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}
#data_val['Survived'] = submit_dt.predict(data_val[data1_x_bin])
</span>

<span class="c1">#bagging w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77990
#submit_bc = ensemble.BaggingClassifier()
#submit_bc = model_selection.GridSearchCV(ensemble.BaggingClassifier(), param_grid= {'n_estimators':grid_n_estimator, 'max_samples': grid_ratio, 'oob_score': grid_bool, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)
#submit_bc.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_bc.best_params_) #Best Parameters:  {'max_samples': 0.25, 'n_estimators': 500, 'oob_score': True, 'random_state': 0}
#data_val['Survived'] = submit_bc.predict(data_val[data1_x_bin])
</span>

<span class="c1">#extra tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990
#submit_etc = ensemble.ExtraTreesClassifier()
#submit_etc = model_selection.GridSearchCV(ensemble.ExtraTreesClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)
#submit_etc.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_etc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}
#data_val['Survived'] = submit_etc.predict(data_val[data1_x_bin])
</span>

<span class="c1">#random foreset w/full dataset modeling submission score: defaults= 0.71291, tuned= 0.73205
#submit_rfc = ensemble.RandomForestClassifier()
#submit_rfc = model_selection.GridSearchCV(ensemble.RandomForestClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)
#submit_rfc.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_rfc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}
#data_val['Survived'] = submit_rfc.predict(data_val[data1_x_bin])
</span>


<span class="c1">#ada boosting w/full dataset modeling submission score: defaults= 0.74162, tuned= 0.75119
#submit_abc = ensemble.AdaBoostClassifier()
#submit_abc = model_selection.GridSearchCV(ensemble.AdaBoostClassifier(), param_grid={'n_estimators': grid_n_estimator, 'learning_rate': grid_ratio, 'algorithm': ['SAMME', 'SAMME.R'], 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)
#submit_abc.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_abc.best_params_) #Best Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0}
#data_val['Survived'] = submit_abc.predict(data_val[data1_x_bin])
</span>

<span class="c1">#gradient boosting w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77033
#submit_gbc = ensemble.GradientBoostingClassifier()
#submit_gbc = model_selection.GridSearchCV(ensemble.GradientBoostingClassifier(), param_grid={'learning_rate': grid_ratio, 'n_estimators': grid_n_estimator, 'max_depth': grid_max_depth, 'random_state':grid_seed}, scoring = 'roc_auc', cv = cv_split)
#submit_gbc.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_gbc.best_params_) #Best Parameters:  {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 50, 'random_state': 0}
#data_val['Survived'] = submit_gbc.predict(data_val[data1_x_bin])
</span>
<span class="c1">#extreme boosting w/full dataset modeling submission score: defaults= 0.73684, tuned= 0.77990
</span>




<span class="c1">#submit_xgb = XGBClassifier()
#submit_xgb = model_selection.GridSearchCV(XGBClassifier(), param_grid= {'learning_rate': grid_learn, 'max_depth': [0,2,4,6,8,10], 'n_estimators': grid_n_estimator, 'seed': grid_seed}, scoring = 'roc_auc', cv = cv_split)
#submit_xgb.fit(data1[data1_x_bin], data1[Target])
#print('Best Parameters: ', submit_xgb.best_params_) #Best Parameters:  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0}
#data_val['Survived'] = submit_xgb.predict(data_val[data1_x_bin])
</span>

<span class="c1">#hard voting classifier w/full dataset modeling submission score: defaults= 0.75598, tuned = 0.77990
#data_val['Survived'] = vote_hard.predict(data_val[data1_x_bin])
</span><span class="n">data_val</span><span class="p">[</span><span class="s">'Survived'</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_hard</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_val</span><span class="p">[</span><span class="n">data1_x_bin</span><span class="p">])</span>


<span class="c1">#soft voting classifier w/full dataset modeling submission score: defaults= 0.73684, tuned = 0.74162
#data_val['Survived'] = vote_soft.predict(data_val[data1_x_bin])
#data_val['Survived'] = grid_soft.predict(data_val[data1_x_bin])
</span>

<span class="c1">#submit file
</span><span class="n">submit</span> <span class="o">=</span> <span class="n">data_val</span><span class="p">[[</span><span class="s">'PassengerId'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">]]</span>
<span class="n">submit</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">"../working/submit.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Validation Data Distribution: </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">data_val</span><span class="p">[</span><span class="s">'Survived'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span> <span class="o">=</span> <span class="bp">True</span><span class="p">))</span>
<span class="n">submit</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 418 entries, 0 to 417
Data columns (total 21 columns):
PassengerId      418 non-null int64
Pclass           418 non-null int64
Name             418 non-null object
Sex              418 non-null object
Age              418 non-null float64
SibSp            418 non-null int64
Parch            418 non-null int64
Ticket           418 non-null object
Fare             418 non-null float64
Cabin            91 non-null object
Embarked         418 non-null object
FamilySize       418 non-null int64
IsAlone          418 non-null int64
Title            418 non-null object
FareBin          418 non-null category
AgeBin           418 non-null category
Sex_Code         418 non-null int64
Embarked_Code    418 non-null int64
Title_Code       418 non-null int64
AgeBin_Code      418 non-null int64
FareBin_Code     418 non-null int64
dtypes: category(2), float64(2), int64(11), object(6)
memory usage: 63.1+ KB
None
----------
Validation Data Distribution:
 0    0.633971
1    0.366029
Name: Survived, dtype: float64
</code></pre></div></div>

<h1 id="ê²°ë¡ ">ê²°ë¡ </h1>

<p>ì‹ ê¸°í•˜ê²Œë„ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ ë³´ë‹¤, ë‚´ê°€ ë§Œë“  íŠ¸ë¦¬ì˜ ì •í™•ë„ê°€ ì‹¤ì œ ì œì¶œì‹œì— ë” ë†’ì•˜ë‹¤. ì´ê²ƒì€, í›ˆë ¨ ë°ì´í„° ì…‹ì˜ ë¶„í¬ì™€ ì œì¶œ ë°ì´í„° ì…‹ì˜ ë¶„í¬ê°€ ë‹¤ë¦„ì„ ë‚˜íƒ€ë‚¸ë‹¤. ì¦‰, CVë¥¼ í†µí•´ ëª¨ë¸ì„ í•™ìŠµí•œë‹¤ í• ì§€ë¼ë„ ì œì¶œìš© ë°ì´í„°ì˜ ë¶„í¬ê°€ ì„±ëŠ¥ì— ì§€ëŒ€í•œ ì—­í• ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì´ë‹¤. ì•Œê³ ë¦¬ì¦˜ì— ì˜ì¡´í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, ì „ì²˜ë¦¬ì™€ feature engineeringì´ ë” ì¤‘ìš”í•œ ê²½ìš°ë„ ë§ë‹¤.</p>

<h3 id="reference">Reference</h3>

<p><a href="https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy#">kaggle Notebook</a></p>

  </section>
  
<footer>
  <div class="tags">
    
    <a class="tag" href="/tags#Data+Science"
      >#Data Science</a
    >
    
    <a class="tag" href="/tags#Machine+Learning"
      >#Machine Learning</a
    >
    
    <a class="tag" href="/tags#kaggle"
      >#kaggle</a
    >
    
  </div>
</footer>


</article>

<!-- Post navigation -->
<div id="post-nav">
           
                                                                                                                                                                                                                                                                          
  <div
    id="previous-post"
    class="post-nav-post"
    onclick="location.href='/ds/ml/2020/05/05/titanic-09-Hyper-parameter-tuning.html';"
  >
    <p>PREVIOUS SERIES</p>
    <p>09: Hyper Parameter Tuning</p>
  </div>
                                                                                                                                                                                                                                                                                                                        
</div>


<!-- Disqus -->

<div class="comments"><div id="disqus_thread"></div>
<script type="text/javascript">
	var disqus_shortname = 'wansook0316';
	(function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to view comments.</noscript>
</div>


<!-- Post navigation -->

</div>

    
<script src="/assets/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">ì´ì „ ë¸”ë¡œê·¸ <a href="https://egg-money.tistory.com">tistory</a>
</p>
</footer>


  </body>
</html>
