<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>완숙의 에그머니🍳</title>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <link>http://localhost:4000/</link>
    <description>얼떨결에 들어왔으니 이것도 인연😌</description>
    <pubDate>Mon, 07 Sep 2020 10:06:53 +0900</pubDate>
    
      <item>
        <title>05: Faster R-CNN</title>
        <link>/ds/dl/2020/09/02/computer-vision-05-Faster-RCNN.html</link>
        <guid isPermaLink="true">/ds/dl/2020/09/02/computer-vision-05-Faster-RCNN.html</guid>
        <description>&lt;h2 id=&quot;핵심-아이디어&quot;&gt;핵심 아이디어&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Region Proposal도 Network안에 포함시키자!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Faster R-CNN의 핵심 아이디어는 Resion Proposal Network(이하 RPN)이다. 기존 Fast R-CNN구조를 계승하면서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;selective search&lt;/code&gt;를 제거하고 RPN을 통해서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Roi&lt;/code&gt;를 계산한다. 이를 통해서 GPU를 통해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Roi&lt;/code&gt;를 계산할 수 있게 되었고, 이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RoI&lt;/code&gt;를 추출하는 것 역시 학습시켜 정확도를 높일 수 있다. 결과적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;selective search&lt;/code&gt;가 2000개 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RoI&lt;/code&gt;를 계산하는데 반해, 800개 정도로 더 높은 정확도를 가진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbUjRYz%2FbtqAWb0p8cv%2Fdx8Ky33sdZtb2RKQ8sQxZK%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;60%&quot; /&gt;&lt;em&gt;Faster R-CNN structure&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그림을 보면 알겠지만, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature map&lt;/code&gt;으로 부터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;selective search&lt;/code&gt;를 거치치 않고 이를 RPN에 전달하여 계산을 진행한다. 여기서 얻은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RoI&lt;/code&gt;로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RoI Pooling&lt;/code&gt;을 진행한 다음 object detection을 진행한다.&lt;/p&gt;

&lt;h1 id=&quot;region-proposal-network&quot;&gt;Region Proposal Network&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fo7PTm%2FbtqAXir1rPy%2FVbzsfY9JMY9N3ixCe3zxb0%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;60%&quot; /&gt;&lt;em&gt;Region Proposal Network structure&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이 그림보다는 순차적으로 된 그림으로 이해하는 것이 쉽다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb7xNNb%2FbtqAYHyrFDU%2FJDkko5dBYTMzZV96AcpakK%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;100%&quot; /&gt;&lt;em&gt;Region Proposal Network structure&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;CNN을 통해 뽑아낸 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature map&lt;/code&gt;을 입력으로 받는다. 어떤 pretrained model을 사용할 지 모르므로 이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HxWxC&lt;/code&gt;로 둔다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature map&lt;/code&gt;에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(3x3)x256&lt;/code&gt; 또는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(3x3)x512&lt;/code&gt; conv 연산을 수행한다. 엄밀히 말하면 C와 256, 512는 같아야 한다. 일단 연산이 가능하다고 가정하자. 이 때, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HxW&lt;/code&gt;가 보존될 수 있게 padding을 1로 설정한다.&lt;/p&gt;

&lt;p&gt;전 과정에서 나온 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature map&lt;/code&gt;을 가지고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;classification&lt;/code&gt;을 위한 확률값과, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bounding box regression&lt;/code&gt; 값을 뽑아낸다. 이 과정에서 너무 많은 연산을 진행하게 되면 모델이 지나치게 무거워 진다. 저자들은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1 x 1 conv&lt;/code&gt;만을 수행하여 예측값을 뽑아내고자 하였다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/37871541/92203883-385bee80-eebd-11ea-9782-e8e3c0e5c95d.png&quot; alt=&quot;image&quot; class=&quot;center&quot; width=&quot;60%&quot; /&gt;&lt;em&gt;Anchor&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;먼저 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Classification&lt;/code&gt;의 경우, 더욱 가볍게 진행하기 위해 물체인지 아닌지를 구분하는 binary &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;classification&lt;/code&gt;을 진행하고자 하였다. 하지만 이 문제는 bounding box와 엮어서 이를 생각해야 하는데, 저자들은 이 단계에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Anchor&lt;/code&gt;라는 개념을 도입하여 이를 진행하였다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Anchor&lt;/code&gt;는 간단하게 사전에 정의해 둔 Box들이다. 총 9개를 사용하였다.&lt;/p&gt;

&lt;p&gt;이 모든 내용을 정리하면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;classification&lt;/code&gt;의 결과는 총 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(HxW)&lt;/code&gt;의 각각의 위치에 제안된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Anchor&lt;/code&gt;(9개)에 대해 물체의 여부(2)를 나타내는 총 18개의 Node를 가져야 한다. 그러기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(1x1)x(2x9)&lt;/code&gt;의 conv 연산을 진행하였다. 결과적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(HxW)x(2x9)&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Feature map&lt;/code&gt;이 나오고, 각각의 노드는 순서대로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(h, w)&lt;/code&gt; 위치에 있는 1번 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;anchor&lt;/code&gt;가 물체일 logit, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(h, w)&lt;/code&gt; 위치에 있는 1번 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;anchor&lt;/code&gt;가 물체가 아닐 logit … 로 정의된다. 최종적으로 이를 확률 값으로 변경해주기 위해 적절히 reshape 해준 다음 Softmax를 적용한다.&lt;/p&gt;

&lt;p&gt;두번째로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bounding Box Regression&lt;/code&gt;을 진행한다. 같은 방법을 사용한다. 이번에는 9개 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;anchor&lt;/code&gt;에 대해 총 4개의 좌표를 수정하기 위한 조절값을 예측해야 하므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(H W)x(4x9)&lt;/code&gt;의 결과를 얻어야 한다. 이번에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regression&lt;/code&gt;이기 때문에 그대로 결과값으로 사용하면 된다.&lt;/p&gt;

&lt;p&gt;앞선 과정은 순차적으로 진행된다. 즉, classification을 먼저 진행하고, 이 결과를 기반으로 물체일 확률을 sorting한다. 이 중 높은 순으로 K개의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;anchor&lt;/code&gt;를 후보군으로 선정한다. 이 후보군에 각각 bounding Box &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Regression&lt;/code&gt;을 진행한다. 마지막으로 Non-Maximum-Suppression을 적용하고, 이것을 기반으로 RoI를 제안한다.&lt;/p&gt;

&lt;p&gt;이러한 방법을 통해서 RoI를 제안하는 Network를 만들었다. 이 후 과정은, 이렇게 만들어진 RoI를 첫번째 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Feature map&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(HxWxC) &lt;/code&gt;에 투영하는 과정을 거친다. 이 부분은 &lt;a href=&quot;https://wansook0316.github.io/ds/dl/2020/09/02/computer-vision-04-Fast-RCNN.html&quot;&gt;Fast R-CNN&lt;/a&gt; 구조와 같다.&lt;/p&gt;

&lt;h3 id=&quot;rpns-loss-function&quot;&gt;RPN’s Loss function&lt;/h3&gt;

&lt;p&gt;RPN은 앞서서 Classification과 Bouding Box Regression을 수행했다. 로스 펑션은 이 두 가지 테스크에서 얻은 로스를 엮은 형태를 취하고 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\{p_i\}, \{t_i\})= {1 \over N_{cls}}\sum_i L_{cls}(p_i, p_i^*) + \lambda {1 \over N_{reg}}\sum_i p_i^* L_{reg}(t_i, t_i^*)&lt;/script&gt;

&lt;p&gt;여기서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;는 하나의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;anchor&lt;/code&gt;를 말한다. $p_i$는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;classification&lt;/code&gt;을 통해서 얻은 해당 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;anchor&lt;/code&gt;가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;object&lt;/code&gt;일 확률을 의미한다. $t_i$는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bounding box regression&lt;/code&gt;을 통해서 얻은 박스 조정 값 벡터를 의미한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt;이 붙은 변수는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ground truth label&lt;/code&gt;에 해당된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;classification&lt;/code&gt;은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;binary cross entropy&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regression&lt;/code&gt;은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;smooth L1 loss&lt;/code&gt;를 사용한다.&lt;/p&gt;

&lt;p&gt;주목해야 할 점은 각각 $N_{cls}$와 $N_{reg}$를 가진다는 점이다. $N_{cls}$는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;minibatch&lt;/code&gt; 사이즈이며 논문에서는 256입니다. $N_{reg}$는 엥커 개수에 해당하며 약 2400개 (256 x 9)에 해당한다. 실제 실험을 진행했을 떄 이부분이 큰 부분을 담당하지는 않는다고 말한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\lambda&lt;/code&gt;는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Classifiaction Loss&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Regression Loss&lt;/code&gt; 사이에 가중치를 조절해주는 부분인데 논문에서는 10으로 설정되어 있어, 사실상 두 로스는 동일하게 가중치가 매겨진다. 이후는 &lt;a href=&quot;https://wansook0316.github.io/ds/dl/2020/09/02/computer-vision-04-Fast-RCNN.html&quot;&gt;Fast R-CNN&lt;/a&gt; 구조와 같다. 이제 남은 것은 어떻게 이 두 네트워크를 학습시키느냐에 대한 것이다.&lt;/p&gt;

&lt;h2 id=&quot;training-method&quot;&gt;Training Method&lt;/h2&gt;

&lt;p&gt;하지만 전체 모델을 한번에 학습시키기란 매우 어려운 작업이다. RPN이 제대로 RoI를 계산해내지 못하는데 뒷 단의 Classification 레이어가 학습될 리가 없다. 여기서 저자들은 4단계에 걸쳐서 모델을 번갈아서 학습시키는 Alternating Training 기법을 취한다. 말이 어렵지 그냥 따로 하고 지지고 볶으면서 학습시킨거다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ImageNet pretrained&lt;/code&gt; 모델을 불러온 다음, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RPN&lt;/code&gt;을 학습시킨다.&lt;/li&gt;
  &lt;li&gt;1 단계에서 학습시킨 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RPN&lt;/code&gt;에서 기본 CNN을 제외한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Region Proposal 레이어&lt;/code&gt;만 가져온다. 이를 활용하여 Fast RCNN을 학습시킨다. 이 때 , 처음 피쳐맵을 추출하는 CNN까지 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fine tune&lt;/code&gt; 시킨다.&lt;/li&gt;
  &lt;li&gt;앞서 학습시킨 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fast RCNN&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RPN&lt;/code&gt;을 불러온 다음, 다른 웨이트들은 고정하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RPN&lt;/code&gt;에 해당하는 레이어들만 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fine tune&lt;/code&gt; 시킨다. 여기서부터 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RPN&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fast RCNN&lt;/code&gt;이 컨볼루션 웨이트를 공유하게 된다.&lt;/li&gt;
  &lt;li&gt;마지막으로 공유하는 CNN과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RPN&lt;/code&gt;은 고정시킨 채, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fast R-CNN&lt;/code&gt;에 해당하는 레이어만 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fine tune&lt;/code&gt; 시킨다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;의의&quot;&gt;의의&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;region proposal&lt;/code&gt;을 한번에 수행&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;한계&quot;&gt;한계&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;여전히 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;real time&lt;/code&gt;이라고 하기에는 무리가 있음&lt;/li&gt;
  &lt;li&gt;여전히 학습과정이 복잡하고 2step 임&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://yeomko.tistory.com/17?category=888201&quot;&gt;갈아먹는 Object Detection [4] Faster R-CNN&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>04: Fast R-CNN</title>
        <link>/ds/dl/2020/09/02/computer-vision-04-Fast-RCNN.html</link>
        <guid isPermaLink="true">/ds/dl/2020/09/02/computer-vision-04-Fast-RCNN.html</guid>
        <description>&lt;h2 id=&quot;핵심-아이디어&quot;&gt;핵심 아이디어&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Feature Extraction, classification, bounding box regression까지 한번에 학습할 수 있는 모델을 만들자!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fast R-CNN은 이전 SSP Net이 가지는 한계점을 극복하는 시도에서 출발한다. SSP Net은 1) Multi stage model이고 2) FC layer 만 학습 시킬 수 있다는 한계점이 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.geeksforgeeks.org/wp-content/uploads/20200219160147/fast-RCNN1.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;Fast R-CNN Architecture&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;알고리즘&quot;&gt;알고리즘&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;pretrained model로 부터 feature map을 추출한다.&lt;/li&gt;
  &lt;li&gt;Selective Search를 통해 찾은 각각의 ROI에 대해 &lt;strong&gt;*ROI Pooling&lt;/strong&gt;을 진행한다. 그 결과로 고정된 크기의 feature vector를 얻는다.&lt;/li&gt;
  &lt;li&gt;feature vector는 FC layer를 통과하고 두개의 branch로 나뉜다.&lt;/li&gt;
  &lt;li&gt;하나의 branch에서는 softmax를 통과하여 해당 ROI가 어떤 물체인지 clasification을 진행한다.&lt;/li&gt;
  &lt;li&gt;다른 branch에서는 bounding box regression을 통해 selective search로 찾은 박스의 위치를 조정한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;핵심 의의는 multi stage model에서 end-to-end로 model을 구성했다는 것에 있다. 결과적으로도 속도, 정확도, 학습 속도 모두를 향상시켰다는데 의의가 있다.&lt;/p&gt;

&lt;h2 id=&quot;roi-polling&quot;&gt;ROI polling&lt;/h2&gt;

&lt;p&gt;Roi pooling의 아이디어는 앞서 보았던 SPP Net과 유사하다. SPP Net은, pretrained model으로 부터 도출되는 feature map으로 부터, 피라미드 filter를 거친 후 이를 vectorize 하여 고정된 개수의 vector를 얻을 수 있었다. 이 아이디어를 조금 변경하여 제시하는 것이 Roi pooling이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmF4V0%2FbtqAVGST2nx%2FNhjfsG6vd89TgIK5bn2Ha0%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;ROI pooling&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;feature map에서 Selective search를 통해 Resion Proposal을 진행한다.&lt;/li&gt;
  &lt;li&gt;이 proposal에 Roi pooling을 진행하여 고정된 형태의 작은 feature map을 만든다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Roi pooling은, Resion Proposal을 고정된 형태의 output 모양으로 바꾼다. (H x W) 크기의 feature map을 output으로 원한다면, proposal을 이에 맞게 칸을 나눈 후, max pooling을 진행한다. 이렇게 되면 항상 같은 크기의 결과를 얻을 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;multi-task-loss&quot;&gt;Multi Task Loss&lt;/h2&gt;

&lt;p&gt;딥러닝을 공부하면서 가장 새롭고 즐거웠던 부분은 손실함수 부분이었다. object detection은 기본적으로 bounding box regression과 classication을 동시에 진행해야 하는 Task이다. 그래서 예전 접근은 multi stage로 이루어졌었다. 하지만 이 Fast R-CNN에서 처음으로 이 두가지 task를 하나로 엮는 방법이 고안된다.&lt;/p&gt;

&lt;p&gt;우리는 이미지로 부터 feature map을 추출했고, 이 feature map에서 Roi를 제안 받아 Roi pooling을 통해 feature vector를 만들었다. 이제 이 벡터로 classification과 bounding box regression을 적용하여 각각의 loss를 얻어내고, 이를 back propagation하여 전체 모델을 학습시키면 된다. 이 두 Task 모두를 반영한 손실함수를 보자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(p, u, t^u, v) = L_{cls}(p, u) + \lambda[u \ge 1]L_{loc}(t^u, v)&lt;/script&gt;

&lt;p&gt;각 변수 하나하나에 대해서 알아보자. 먼저, $p$ 는, Softmax를 통해 얻어낸 $K+1$ 개의 확률값이다.(이산 확률 분포) $K+1$인 이유는 K개의 object와 배경(아무 물체도 아님)을 추가한 것이다. $u$는 해당 Roi의 ground truth label 벡터이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p = (p_0, ..., p_n,..., p_k)\\
u = (0, ..., 1, ..., 0)&lt;/script&gt;

&lt;p&gt;다음으로는 &lt;a href=&quot;https://wansook0316.github.io/ds/dl/2020/09/02/PaperReview-01-RCNN.html&quot;&gt;bounding box regression&lt;/a&gt;을 진행한다. 고정 처리된 feature map을 가지고 regression을 했을 때 결과는, 각각의 class (K + 1) 에 대해 각각 x, y, w, h를 조정하는 파라미터 $t^k$를 리턴한다. 말로 풀어보면 다음과 같다. feature map으로 부터 1번 클래스 일 때 (x, y, w, h)를 ($t_x$, $t_y$, $t_w$, $t_h$) 로 변화시켜. 2번 클래스 일때는 …(중략). 이 중에서 우리가 하고 싶은 것은, 이 결과를 바탕으로 이를 수정하는 loss function을 만들고 싶은 것이므로 이 결과들 중 ground truth에 속하는 u번째 t만 가져와서 사용한다. $v$는 ground truth bounding box 조절 값에 해당한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;t^k = (t^k_x, t^k_y, t^k_w, t^k_h)\\
t^u = (t^u_x, t^u_y, t^u_w, t^u_h)\\&lt;/script&gt;

&lt;p&gt;그렇다면 이제 각각의 loss function에 대해서 알아보자. 먼저 classification loss 는 log loss를 사용한다. 못맞출 수록 패널티를 크게 준다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{cls}(p, u) = -logp_u&lt;/script&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;location&lt;/code&gt;을 담당하는 loss는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{loc}(t^u, v) = \sum_{i \in {x, y, w, h}}smooth_{L_1}(t^u_i - v_i)&lt;/script&gt;

&lt;p&gt;bounding box를 만들기 위한 예측 조절값에서 실제 조절값을 smooth L1을 통과시킨 것의 합을 사용한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
smooth_{L_1}(x) =

\begin{cases}
0.5x^2 &amp; \mbox {if }\left| x \right| &lt; 1 \mbox{ is even} \\
\left| x \right|-0.5 &amp; otherwise
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;저자들은 실험 과정에서 라벨 값과 지나치게 차이가 많이 나는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outlier&lt;/code&gt;가 많았고, 이런 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outlier&lt;/code&gt;에 민감하게 반응하는 L2 loss를 그대로 사용할 경우 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gradient explode&lt;/code&gt;현상이 발생하는 것을 확인했다고 한다. 이를 제어하기 위해 custom한 loss function을 사용했다.&lt;/p&gt;

&lt;h2 id=&quot;backpropagation-through-roi-pooling-layer&quot;&gt;Backpropagation through RoI Pooling Layer&lt;/h2&gt;

&lt;p&gt;이제 네트워크를 학습하면 된다. 그런데 이전의 SSP Net을 보면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature map&lt;/code&gt;을 뽑아낸 후, SSP를 거쳐 나온 vector들에 대해 FC layer를 구성하고, 이 단계만 학습시켰던 것을 기억할 거다.(fine tuning) 위 논문에서 저자들은, 이미지의 특징을 추출하는 가장 중요한 역할인 CNN이 학습될 수 없다는 것에 집중한다. 즉, 어느 단계까지 fine tuning을 진행할 것인지, 또 그 fine funing을 진행할 경우 학습이 진행이 되는지(역전파가 전달이 되는지)를 이론적으로 검증한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\partial L \over \partial x_i } = \sum_r \sum_j [i = i^*(r, j)]{\partial L \over \partial y_{rj} }&lt;/script&gt;

&lt;p&gt;$x_i$라고 하는 것은 CNN을 통해 추출된 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature map&lt;/code&gt;에서 하나의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature&lt;/code&gt;를 의미하고 이는 실수이다. 전체 Loss에 대해서 이 피쳐 값의 편미분 값을 구하면 그 값이 곧 xi에 대한 loss 값이 되며 역전파 알고리즘을 수행할 수 있다. 이제 피쳐 맵에서 RoI를 찾고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RoI Pooling&lt;/code&gt;을 적용하기 위해서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;H x W&lt;/code&gt; 크기의 grid로 나눈다. 이 그리드들을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sub-window&lt;/code&gt;라 부르며, 위 수식에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;j&lt;/code&gt;란 몇번째 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sub-window&lt;/code&gt;인지를 나타내는 인덱스이다. $y_{rj}$는 이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Roi Pooling&lt;/code&gt; 을 통과하여 최종적으로 얻어진 ouput의 값이며 이 역시 실수이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcHlzBy%2FbtqAThsNYhK%2FVKc46d2mKurHG7foMCN2wk%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;60%&quot; /&gt;&lt;em&gt;Back Propagation through RoI Pooling&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$x_i$ 가 최종 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prediction&lt;/code&gt; 값에 영향을 주려면 $x_i$가 속하는 모든 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Roi&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sub-window&lt;/code&gt; 에서 해당 $x_i$가 최댓값이 되야 한다. $i^*(r, j)$란 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Roi&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sub-window index j&lt;/code&gt;가 주어졌을 때, 최대 피쳐 값의 인덱스를 말한다.&lt;/p&gt;

&lt;p&gt;즉 수식을 보면 $[i = i^*(r, j)]$ 이렇게 표현되어 있는데, 최대 패쳐 인덱스가 내가 구하길 원하는 피쳐와 같을 때는 1을 return, 아니면 0 을 return 하라는 의미이다. 결과적으로 우리는 $\partial L \over \partial y_{rj}$ 이 값을 가지고 있고, 발생하는 모든 이 값을 더해서 적용시켜주면 $x_i$에 대한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gradient&lt;/code&gt;를 구할 수 있다.&lt;/p&gt;

&lt;p&gt;종합하면, 우리는 앞서 구한 multitask loss를 RoI Pooling layer를 통과하여 CNN 단까지 fine-tuning 할 수 있다. 저자드은 실험을 통해서 실제로 CNN단 까지 fine tuning 하는 것이 성능 향상에 도움이 되었다는 실험 결과를 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbadZIp%2FbtqAVIwqRP6%2FW9hTlTIcKm6JNlFDTsWf4K%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;60%&quot; /&gt;&lt;em&gt;fine tuning depth에 따른 성능 변화&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위 실험 결과는 fine-tuning 하는 깊이를 조절해가며 성능 변화를 실험한 것이다. CNN의 단을 깊이 학습시킬 수록 성능이 향상되었으며, 이 때 테스트에 소요되는 시간 변화는 거의 없는 것을 확인할 수 있다. 즉, CNN 단을 Object Detection에 맞게끔 fine-tuning 하는 것이 성능 향상의 키 포인트였다.&lt;/p&gt;

&lt;h2 id=&quot;의의&quot;&gt;의의&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;end-to-end&lt;/code&gt; 모델 제안&lt;/li&gt;
  &lt;li&gt;학습 단계 간소화&lt;/li&gt;
  &lt;li&gt;정확도, 성능 개선&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;한계&quot;&gt;한계&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;region proposal을 selective search를 사용
    &lt;ul&gt;
      &lt;li&gt;이는 CPU 연산으로만 가능하기 때문에 병목이 발생&lt;/li&gt;
      &lt;li&gt;이 부분이 inference를 수행하는데 있어 가장 많은 시간을 차지함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://yeomko.tistory.com/15?category=888201&quot;&gt;갈아먹는 Object Detection [3] Fast R-CNN&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>03: Spatial Pyramid Pooling Network</title>
        <link>/ds/dl/2020/09/02/computer-vision-03-Spatial-Pyramid-Pooling-Network.html</link>
        <guid isPermaLink="true">/ds/dl/2020/09/02/computer-vision-03-Spatial-Pyramid-Pooling-Network.html</guid>
        <description>&lt;h2 id=&quot;핵심-아이디어&quot;&gt;핵심 아이디어&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;입력 이미지의 크기나 비율에 관계없이 CNN 학습은 불가한가?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fast R-CNN으로 넘어가기전 상당히 많은 아이디어를 가져온 논문이다. 이전의 R-CNN을 보게되면, proposal roi가 CNN에 들어가기 전에 입력 이미지를 바꿔주어야 하는 한계가 존재했다. 여기서 저자들은 의문을 갖는다. 이 제한 요소를 없앤 상태로 CNN을 학습시키는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdb1FzH%2FbtqASyVypzb%2FGpCrnYjeKY1Si6LjftCoO0%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;SPPNet의 핵심 아이디어&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;사실 CNN의 입력이미지 크기는 고정될 필요가 없다. CNN의 핵심 아이디어는 filter를 가지고 연산을 수행하는 것이고, 이것의 연산 방식은 sliding window 방식으로 진행된다. 하지만, 이 입력 이미지의 크기가 고정이어야 하는 이유는, 마지막에 도출되는 fully connected layer의 크기가 고정적으로 나와야 하기 때문이다. 이 문제점으로 부터 SPPNet가 제안된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;입력 이미지 상관 없이 통과시키고, FC 전에 polling을 통해서 동일한 크기로 만들자!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;굉장히 단순한 방법을 제안하였다. (…) 이런 방식을 사용할 경우, 원본 이미지의 특징을 고스란히 간직한 feature map을 얻을 수 있다. 추가적으로 비율도 조절하지 않기 때문에, 사물의 크기에 따른 변화도 감지가 가능하다.&lt;/p&gt;

&lt;p&gt;위의 그림을 보면 Crop 후 conv에 넣는 것이 아니고, feature map을 만든 후, 이를 SSPNet에 넣어 모양을 맞춘 후에 output을 만드는 것을 볼 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;알고리즘&quot;&gt;알고리즘&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;전체 이미지를 pretrained model을 통과시켜 feature map을 추출한다.&lt;/li&gt;
  &lt;li&gt;해당 feature map으로 부터 selective search를 통해 ROI를 뽑아낸다. 이 때 발생하는 ROI는 모두 크기와 비율이 다르다. 여기서 &lt;strong&gt;&lt;em&gt;SSPNet&lt;/em&gt;&lt;/strong&gt;을 적용하여 고정된 크기의 feature vector를 추출한다.&lt;/li&gt;
  &lt;li&gt;FC layer를 통과시킨다.&lt;/li&gt;
  &lt;li&gt;앞서 추출한 벡터로 각 이미지 클래스 별로 SVM을 학습시킨다.&lt;/li&gt;
  &lt;li&gt;마찬가지로 해당 벡터로 bounding box regressor를 학습시킨다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;spatial-pyramid-pooling&quot;&gt;Spatial Pyramid Pooling&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/proxy/sVOitw5Jpud7QnLoR5r3TzlOWJYSEFkRCCx1MlG71WCIG5BP8I8B5EZTveQKsJ5ign3DT00vzGB5dEoYYjrfsXFbA1D6laCS&quot; alt=&quot;&quot; class=&quot;center&quot; /&gt;&lt;em&gt;출처 : http://kaiminghe.com/eccv14sppnet/index.html&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 어떤 방식으로 SPP가 돌아가는지 이해해야 한다. 먼저 CNN을 거친 feature map을 input으로 받는다. 그리고 이것을 미리 정해져 있는 영여긍로 나누어 준다. 위의 예시에서는 4x4, 2x2, 1x1 3개의 영역이 적용되어 있고, 이 각각을 하나의 피라미드라 부른다. 즉, 3개의 피라미드를 설정한 것.&lt;/p&gt;

&lt;p&gt;이 피라미드는 4x4 짜리 고정된 CNN 필터 같은 것이 아니다. 어떠한 input이 들어오더라도 4x4 격자로 만든다는 표현이 더 맞는 표현이다. 예를 들어 입력이 64 x 64 x 256 크기의 피쳐 맵이 들어온다고 했을 때, 4x4의 피라미드의 bin의 크기는 16x16이 된다.&lt;/p&gt;

&lt;p&gt;이제 이 각각의 bin에서 가장 큰 값만 추출하는 max pooling을 수행하고, 그 결과를 &lt;strong&gt;쭉 이어 붙인다&lt;/strong&gt;. 입력 feature map의 채널 크기가 k, bin의 개수를 M이라 한다면, 해당 SSP의 output은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k x M&lt;/code&gt;의 크기를 가진 1차원의 벡터가 될 것이다.&lt;/p&gt;

&lt;h2 id=&quot;한계&quot;&gt;한계&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;여전히 multi stage model이다.&lt;/li&gt;
  &lt;li&gt;여전히 SVM, selective search를 사용한다.&lt;/li&gt;
  &lt;li&gt;feature map을 만들어내는 network를 학습시키지 못한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kcPAGIgBGRs&amp;amp;list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br&amp;amp;index=12&quot;&gt;PR-012: Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>02: R-CNN</title>
        <link>/ds/dl/2020/09/02/computer-vision-02-RCNN.html</link>
        <guid isPermaLink="true">/ds/dl/2020/09/02/computer-vision-02-RCNN.html</guid>
        <description>&lt;h1 id=&quot;computer-vision의-task&quot;&gt;Computer Vision의 Task&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://image.slidesharecdn.com/pr12fasterrcnn170528-170802143120/95/faster-rcnn-pr012-3-638.jpg?cb=1504447138&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;
이중 Object Detection에 해당하는 문제이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://image.slidesharecdn.com/pr12fasterrcnn170528-170802143120/95/faster-rcnn-pr012-5-638.jpg?cb=1504447138&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;속도가 느려보여도 정확도 측면에서 높은 것을 알 수 있다.&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;r-cnn&quot;&gt;R-CNN&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://image.slidesharecdn.com/pr12fasterrcnn170528-170802143120/95/faster-rcnn-pr012-6-638.jpg?cb=1504447138&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;
&lt;img src=&quot;https://image.slidesharecdn.com/pr12fasterrcnn170528-170802143120/95/faster-rcnn-pr012-7-638.jpg?cb=1504447138&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;region proposal을 진행한다.&lt;/li&gt;
  &lt;li&gt;CNN에 각각 넣는다. -&amp;gt; &lt;strong&gt;느리다&lt;/strong&gt;, CNN을 사용하기 때문에 입력 크기가 동일해야 한다.(warpping)&lt;/li&gt;
  &lt;li&gt;CNN의 마지막 feature map에서 SVM을 사용하여 구분한다.&lt;/li&gt;
  &lt;li&gt;또한 입력으로 주어진 bounding box를 조정하기 위해 regression을 진행한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;region-proposal&quot;&gt;Region Proposal&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://image.slidesharecdn.com/pr12fasterrcnn170528-170802143120/95/faster-rcnn-pr012-8-638.jpg?cb=1504447138&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;initial bounding box를 selective search를 사용하여 뽑아낸다. -&amp;gt; 느리다.&lt;/p&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;pretrained model = alexnet for ImageNet classification dataset
    &lt;ul&gt;
      &lt;li&gt;이미지넷에서 사전 훈련된 알렉스 넷을 사용했다. 마지막단을 잘라서 사용한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;가지고 있는 데이터를 넣어서 훈련한다.&lt;/li&gt;
  &lt;li&gt;여기서 발생한 마지막 feature map을 가지고 와서 classification, bounding box regression 을 진행한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이러한 방법은, 두가지 문제를 발생시킨다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;속도&lt;/li&gt;
  &lt;li&gt;마지막 단의 feature map을 사용하기 때문에 back propagation을 통한 학습이 불가하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bounding-box-regression&quot;&gt;Bounding-Box Regression&lt;/h2&gt;

&lt;p&gt;Box는 centerX, centerY, Width, Height로 표현된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P^i = (P^i_x, P^i_y, P^i_w, P^i_h) \\
\\\\
G = (G_x, G_y, G_w, G_h)&lt;/script&gt;

&lt;p&gt;우리의 목적은 $P^i$ 박스를 최대한 G에 가깝게 이동시키는 함수를 학습시키는 것이다. 이를 표현해보면 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d_x(P), d_y(P), d_w(P), d_h(P)&lt;/script&gt;

&lt;p&gt;x, y의 경우는 평행이동이 연산의 전부이기 때문에 linear 연산으로 처리가 가능하다. 반면 너비와 높이는 확대, 축소 변환이 필요하다. 단순한 확대 축소 연산을 사용하게 되면, 추후에 backpropagation을 통한 학습이 어려워지기 때문에 여기서는 exp를 사용했다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{G_x} = P_wd_x(P) + P_x
\hat{G_y} = P_hd_y(P) + P_y
\hat{G_w} = P_wexp(d_w(P))
\hat{G_h} = P_hexp(d_h(P))&lt;/script&gt;

&lt;p&gt;왜 굳이 식을 이렇게 만들었냐 보다는, 이러한 방식으로 제안을 하려고 했다고 생각해보자. P에 대한 변수는 초기에 제안하는 것이므로, 우리는 함수 $d_*(P)$ 가 어떤 녀석인지 아는 것이 목표이다. 그리고 이 함수를 알아내는 과정은 deep learning network를 사용하여 만들 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d_*(P) =  {w}^T_*\phi_5(P)&lt;/script&gt;

&lt;p&gt;여기서 $\phi_5(P)$는 pretraioned model의 가장 마지막 feature map을 의미한다. 결국 feature맵에 선형 연산을 추가하여 원하는 함수를 구한다.&lt;/p&gt;

&lt;p&gt;그렇다면, 이제는 문제가 변화했다. ground truth에서 발생하는 함수와 제안된 방법의 함수 $w^T_* \phi_5(P)$ 의 가중치 $w^T_*$ 를 구하는 문제이다.&lt;/p&gt;

&lt;p&gt;ground truth에서 발생하는 값인 $t^i_*$는 각각의 사진 한장에 대해서 고정되어 있다. 이를 반영한 손실 함수는 다음과 같다. 저자들은 람다를 1000으로 설정하였다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_* = \underset{\hat{ w_*}}{argmin}\sum_i^N(t^i_*-{\hat{ w_*}^T}\phi_5(P))^2+\lambda \lVert {\hat{ w_*}^T} \rVert ^2&lt;/script&gt;

&lt;h2 id=&quot;한계&quot;&gt;한계&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;느리다.&lt;/li&gt;
  &lt;li&gt;SVM은 CNN을 훈련시키지 못한다.&lt;/li&gt;
  &lt;li&gt;Multostage Training Pipeline이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kcPAGIgBGRs&amp;amp;list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br&amp;amp;index=12&quot;&gt;PR-012: Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>01: 컴퓨터 비전 용어 정리</title>
        <link>/ds/dl/2020/09/02/computer-vision-01-%EC%9A%A9%EC%96%B4-%EC%A0%95%EB%A6%AC.html</link>
        <guid isPermaLink="true">/ds/dl/2020/09/02/computer-vision-01-%EC%9A%A9%EC%96%B4-%EC%A0%95%EB%A6%AC.html</guid>
        <description>&lt;h2 id=&quot;descripter&quot;&gt;Descripter&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;이미지를 비교하기 위해 동일한 방법을 통해 하나의 비교 대상으로 만드는 것&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/593/1*K68boX7fmtsYmyG2LlcmhQ.jpeg&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;descripter&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;두 가지 이미지가 있다. 이 두가지 이미지가 비슷한지 아닌지를 구분하기 위해 만든 것이 descripter이다. 위의 그림에서는 픽셀의 값들을 기반으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gradients&lt;/code&gt;를 구해 이를 grid에 plot하여 표현하였다. 여기서 이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gradients&lt;/code&gt;를 descripter로 사용했다고 말한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9LBYd%2FbtqA2VjFlEl%2FwHdGhznBKKUkKYuufpfaO1%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;HOG algorithm&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;예를 들어 HOG 알고리즘은 각 pixel에서 gradient를 구하고 이 값들을 총 8가지 방향으로 매핑한 후, 히스토그램을 생성한다. 이렇게 추출돈 Feature vector는 keypoint이고 이를 기반으로 bounding box등을 만드는데 활용한다. 요즘은 이 feature mapCNN을 통해 생성한다.&lt;/p&gt;

&lt;h2 id=&quot;region-proposal&quot;&gt;Region Proposal&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;이미지로부터 영역을 선택하기 위해 사용되는 알고리즘&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;기존의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sliding window&lt;/code&gt;방식은 매우 비효율적이었고, 이를 개선한 방법이다. “물체가 있을 법한” 영역을 빠른 속도로 찾아내는 알고리즘이다. 보편적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;selective search&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;edge box algorithm&lt;/code&gt;이 있다. 하지만 이 역시도 추후에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;end-to-end&lt;/code&gt; 방식으로 개선된다.&lt;/p&gt;

&lt;h2 id=&quot;roiregion-of-interest&quot;&gt;RoI(Region of Interest)&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;이미지내에서의 관심 영역&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;원래 input에서 잘라낸 관심 영역들을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RoI&lt;/code&gt;라 한다.&lt;/p&gt;

&lt;h2 id=&quot;caption-generation&quot;&gt;Caption generation&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;이미지로 부터 문장을 생성하는 것&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 연구는 Human-object interaction에 기초하여 연구되고 있다.&lt;/p&gt;

&lt;h2 id=&quot;smooth-l1-loss&quot;&gt;Smooth L1 Loss&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
smooth_{L_1}(x) =

\begin{cases}
0.5x^2 &amp; \mbox {if }\left| x \right| &lt; 1 \mbox{ is even} \\
\left| x \right|-0.5 &amp; otherwise
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;L1, L2 Loss는 생략하였다. 수식에서의 x는 $|y-\hat{y}|$로 정답 label과 차이이다. 오차가 작은 부분은 제곱을 사용했고, 그렇지 않은 부분에서는 직선을 사용했다. 이러한 방식은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1 Loss&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2 Loss&lt;/code&gt;의 장점을 결합한 형태이다. 즉, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;error&lt;/code&gt;가 클경우 안정적으로 loss를 감소시키고($x$)
, 작을 경우에는 L2 Loss를 사용하여 업데이트 과정중 진동을 감소시킨다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbz02fP%2FbtqA3eDjKfT%2FP8HHzmOivZTkIeGAZnPwBK%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;iou-intersection-over-union&quot;&gt;IOU (Intersection over union)&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;예측한 bounding box와 ground truth box간의 겹치는 넓이 비율&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fqtl0q%2FbtqA6pYBQLE%2FjZeHHTpFgEXMkGrQCXDhqK%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;100%&quot; /&gt;&lt;em&gt;IOU&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이것은 사진으로 직관적으로 이해할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;ablation-study&quot;&gt;Ablation study&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;기존 모델에서 feature를 제거하면서 영향력을 확인하는 것&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature&lt;/code&gt;는 변수보다는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;network&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;layer&lt;/code&gt;등을 말한다.&lt;/p&gt;

&lt;h2 id=&quot;jittered-examples&quot;&gt;Jittered examples&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;IoU를 기준으로 사용하겠다고 판단한 bounding box&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bounding box regression&lt;/code&gt;을 진행한 후에 각각의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;proposal&lt;/code&gt;에 대해 예측한 결과 중 학습에 재사용하기 위한 샘플을 걸러낼 때 사용되는 개념이다. 예를 들어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IoU&lt;/code&gt;가 0.5이상 인 샘플을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;positive sample&lt;/code&gt;이라 정의할 경우, 이 샘플을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Jittered examples&lt;/code&gt;이라 한다.&lt;/p&gt;

&lt;h2 id=&quot;non-maximum-suppression-nms&quot;&gt;Non-maximum suppression (NMS)&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;동일한 클래스라 판명된 bounding box들 중 중복을 제거하는 방법&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://blog.kakaocdn.net/dn/dzskGm/btqx0sScMdc/Qs7dKbEzZIFR0U5MxzsAP0/img.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;Non-maximum suppression (NMS)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;알고리즘은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;동일한 클래스에 대해 검출된 bounding box들을 confidence 순서로 정렬한다.&lt;/li&gt;
  &lt;li&gt;가장 confidence가 높은 bounding box와 IoU가 일정 이상인 bounding box는 동일 물체를 detect했다 판단하여 지운다.
    &lt;ul&gt;
      &lt;li&gt;가장 confidence높은것만 남기고 보통 0.5이상 box들을 지운다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ohem-online-hard-example-mining&quot;&gt;OHEM (Online Hard Example Mining)&lt;/h2&gt;

&lt;p&gt;먼저, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hard Example&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Easy Example&lt;/code&gt;의 개념부터 알아보자. 사람인지 아닌지를 분류하는 모델이 있다고 하자. 우리의 목적은 이 모델을 훈련시키는 것이다. 대부분의 사람 이미지는 분류하도록 만들었다. 하지만 사람 동상과 같은 샘플에 대해서는 모델이 구분하기 어려울 것이다. 이러한 상황에서 일반적으로 잘 동작하는 샘플을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Easy Example&lt;/code&gt;, 사람 동상 이미지를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hard Example&lt;/code&gt; 이라 한다. 이런 것들을 제대로 훈련하기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hard Example&lt;/code&gt;에 대해 가중치를 주거나 해서 모델을 훈련시켜야 할 것이다.&lt;/p&gt;

&lt;p&gt;다음은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;positive&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;negative&lt;/code&gt;에 대한 개념이다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;positive&lt;/code&gt;는 문제에서 내가 원하는 클래스를 의미한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;positive sample&lt;/code&gt;은 bounding box의 label이 사람인 것을 의미하고, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;negative sample&lt;/code&gt;은 배경임을 의미한다.&lt;/p&gt;

&lt;p&gt;그렇다면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hard negative&lt;/code&gt;란, &lt;strong&gt;실제로는 배경인데, 사람이라고 예측한 sample&lt;/strong&gt;이다. 반대로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;easy negative&lt;/code&gt;는 실제로 배경이며 배경으로 예측했음을 의미한다.&lt;/p&gt;

&lt;p&gt;즉, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hard negative sample&lt;/code&gt;은, 네거티브 샘플이라고 보기 어렵다라는 의미이다. 해당 샘플에 대해 &lt;em&gt;배경&lt;/em&gt;이라고 말해야 하는데, confidence는 높게 나오는 상황을 말한다.&lt;/p&gt;

&lt;p&gt;우리가 알아볼 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;object detection&lt;/code&gt;문제에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resion proposal&lt;/code&gt;을 통해 여러가지 후보를 선택하게 된다. 이 후보군의 대부분은 배경이라고 말해야 하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;easy negative sample&lt;/code&gt;이 차지하고 있다. 또한 사람이라고 말해야 하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;positive sample&lt;/code&gt;의 개수는 매우 부족하다. 보통 이러한 상황에서는 모집단의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;balance&lt;/code&gt;를 맞추는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resampling&lt;/code&gt;을 진행하거나, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boosting&lt;/code&gt;알고리즘으로 진행하게 된다. 하지만 이것은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;label&lt;/code&gt;의 불균형을 알고있고, 이를 처리할 수 있을 때 가능하다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;detection&lt;/code&gt;문제는 후보군의 label을 모르기 때문에 이 방법은 사용할 수 없다. 그렇다면 만약 이 상황에서 그대로 훈련을 진행하게 되면, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;easy negative sample&lt;/code&gt;의 양이 너무 많기 때문에 &lt;strong&gt;&lt;em&gt;배경을 배경이라 하는 예측&lt;/em&gt;&lt;/strong&gt;만이 대다수를 이루고, 이에 대해서만 학습을 진행하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbF24Qv%2FbtqB1HkB3mV%2FUSiGT6rJJmblKDwhxYGVV0%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;100%&quot; /&gt;&lt;em&gt;Cross Entropy &amp;amp; Binary Cross Entropy&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 Classification에서 사용하는 Loss 함수는 Cross Entropy 이다. 이러한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;imbalance&lt;/code&gt;를 고려하여 업데이트를 하지 않기 때문에, 기존의 방식을 사용할 경우, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;background&lt;/code&gt;만 잘 맞추는 요상한 모델이 결과로 도출된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbT09uA%2FbtqCPAKK5gc%2FI0CM7QEhghXMx9kbptJbJk%2Fimg.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;100%&quot; /&gt;&lt;em&gt;OHEM (Online Hard Example Mining)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;우리는 결과적으로 배경은 배경이라하고, 사람은 사람이라고 하는 좋은 모델을 제작해야 한다. 그러기 위해서는 후보군의 대부분을 차지하고 있는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;easy negative sample&lt;/code&gt;에 대해서 업데이트는 줄이고, 배경인데 배경이 아니라고 하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hard negative sample&lt;/code&gt;에 대해 주된 업데이트를 진행해야 한다. 이를 위해 제안된 방법이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OHEM (Online Hard Example Mining)&lt;/code&gt;이다. 결과적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;positive sample&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hard negative sample&lt;/code&gt;을 가지고 문제를 해결한다. 이와 같은 불균형 문제를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Class Imbalance&lt;/code&gt;라 한다.&lt;/p&gt;

&lt;h2 id=&quot;focal-loss&quot;&gt;Focal Loss&lt;/h2&gt;

&lt;p&gt;위의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OHEM&lt;/code&gt;과 비슷하게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;class Imbalance&lt;/code&gt;를 해결하기 위한 방법이다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss function&lt;/code&gt;을 수정하여 이를 해결한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
p_t =

\begin{cases}
p &amp; \mbox {if } y = 1 \\
1-p &amp; otherwise
\end{cases}
\\

FL(p_t) = -(1-p_t)^\gamma log(p_t) %]]&gt;&lt;/script&gt;

&lt;p&gt;이런 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss funtion&lt;/code&gt;을 이해하는 가장 좋은 방법은 양 극단치를 넣어보는 것이다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y=1&lt;/code&gt;일 경우, ground truth가 사람인 경우에는 해당 class가 나올 확률을 그대로 넣어준다. 즉 $p_t = p$ 이다. 그렇다면 만약 잘 맞췄을 경우에는 loss가 0에 가까워진다. 결과적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;postitive&lt;/code&gt;에 대해 잘 예측할 경우 loss를 작게 주고, 그렇지 않은 경우 loss를 크게 준다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y!=1&lt;/code&gt;인 경우, $p_t = 1-p$이고, 그렇게 될 경우 $FL(p_t) = -p\gamma log(1-p)$이다. cross entropy식에서 앞항과 뒤 항의 변형을 통해 log함수가 가지는 특징을 사용했다. 잘 예측할 경우 loss를 크게 주고, 그렇지 않을 경우 loss를 작게준다. 다만 log 함수에 엮여 있는 부분은 잘 예측했을 경우에 더 큰 loss값을 주게 되므로, 이 식의 의도는, 너무 잘 예측하는 데이터(p가 계속 너무 높게 나옴)의 영향력을 줄이기 위한 것이 강하다. 실제로 OHEM 보다 성능이 더 좋다고 한다.&lt;/p&gt;

&lt;h2 id=&quot;contextual-feature&quot;&gt;Contextual feature&lt;/h2&gt;

&lt;p&gt;2d image에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;contextual based classification&lt;/code&gt;은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pixel&lt;/code&gt;의 주변 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;neighborhood&lt;/code&gt; 과의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relationship&lt;/code&gt;에 초점을 맞춘 approach를 뜻한다. 즉, 어떤 특정 pixel의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;contextual feature&lt;/code&gt;는 주변 pixel들과의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relationship&lt;/code&gt;에 기반해서 추출한 feature를 뜻한다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://ganghee-lee.tistory.com/33&quot;&gt;컴퓨터비전에서의 기본 용어 및 개념 정리&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>01: Nginx</title>
        <link>/ds/server/2020/09/01/Server-01-Nginx.html</link>
        <guid isPermaLink="true">/ds/server/2020/09/01/Server-01-Nginx.html</guid>
        <description>&lt;h1 id=&quot;nginx란&quot;&gt;nginx란?&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;트래픽이 많은 웹사이트를 위해 설계한 비동기 이벤트 기반 구조의 웹서버 소프트웨어&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;러시아의 프로그래머,이고르 시쇼브가 Apache의 C10K Problem(하나의 웹서버에 10,000개의 클라이언트의 접속을 동시에 다룰 수 있는 기술적인 문제)를 해결하기 위해 만든 Event-driven구조의 HTTP, Reverser Proxy, IMAP/POP PROXY server를 제공하는오픈소스 서버 프로그램이다.&lt;/p&gt;

&lt;h1 id=&quot;apache-vs-nginx&quot;&gt;Apache vs nginx&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apache&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;쓰레드 / 프로세스 기반 구조로 요청 하나당 쓰레드 하나가 처리하는 구조&lt;/li&gt;
  &lt;li&gt;사용자가 많으면 많은 쓰레드 생성, 메모리 및 CPU 낭비가 심함&lt;/li&gt;
  &lt;li&gt;하나의 쓰레드 : 하나의 클라이언트 라는 구조&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;nginx&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;비동기 Event-Driven 기반 구조.&lt;/li&gt;
  &lt;li&gt;다수의 연결을 효과적으로 처리가능.&lt;/li&gt;
  &lt;li&gt;대부분의 코어 모듈이 Apache보다 적은 리소스로 더 빠르게 동작가능&lt;/li&gt;
  &lt;li&gt;더 작은 쓰레드로 클라이언트의 요청들을 처리가능&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;thread와-event-driven-방식&quot;&gt;thread와 Event-driven 방식&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://mblogthumb-phinf.pstatic.net/MjAxNzAzMjZfMTI2/MDAxNDkwNDk1NjMxNzU4.wrfzv-j7_pzF4GorDTt52dZPzLcUPwnu6JJkgvD53r0g.2xqzw_4Z557pZPaKMbg5pCF3CfvyQtpBqnZrA1p9qjYg.GIF.jhc9639/mighttpd_e01.gif.gif?type=w800&quot; alt=&quot;thread 방식&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mblogthumb-phinf.pstatic.net/MjAxNzAzMjZfMTM3/MDAxNDkwNDk1NjMxNzgy.OHZ33nerX_6Hc92Mg_xjr51acwwi1P_mq3SIl7Cuhisg.niRsQQVM5CwGpXKcdOxl3bkNsmfBkqGV1ajcBpV6CvQg.GIF.jhc9639/mighttpd_e02.gif.gif?type=w800&quot; alt=&quot;Event-driven 방식&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림만 봐도 딱 알겠지만, Event-driven 방식은 java-script에서와 같이 비동기 이벤트를 처리하는 방식으로 구동된다. 그렇기 때문에 자원을 효율적으로 사용한다.&lt;/p&gt;

&lt;p&gt;그렇지 않아도 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;node.js&lt;/code&gt;의 창시자 라이언 달은 nginx를 프록시 서버로 앞단에 두고, node.js를 뒤쪽에 놓는게 버퍼 오버플로우 공격을 방지할 수 있다고 하였다.&lt;/p&gt;

&lt;h2 id=&quot;버퍼-오버플로우&quot;&gt;버퍼 오버플로우&lt;/h2&gt;

&lt;p&gt;버퍼는 보통 데이타가 저장되는 메모리 공간을 뜻한다. 이 때, 메모리 공간을 벗어나는 경우 오버플로우가 되고 이 때 사용되지 않아야 할 영역에 데이터가 덮어씌워져 주소, 값을 바꾸는 공격이다.&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;h3 id=&quot;버퍼-오버플로우로-인한-큰-이슈--하트블리드사태&quot;&gt;버퍼 오버플로우로 인한 큰 이슈 : 하트블리드사태&lt;/h3&gt;

&lt;p&gt;즉, 실제포트를 숨기고 nginx의 80포트를 통해서 프록시하면 보안적으로 막을 수 있다는 것인데 이것 말고도 정적자료에 대한 gzip압축, 그리고 앞단에서의 로그를 저장할 수 있다.&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>03: image 생성, 업로드</title>
        <link>/ds/docker/2020/09/01/Docker-04-image%EC%83%9D%EC%84%B1-%EC%97%85%EB%A1%9C%EB%93%9C.html</link>
        <guid isPermaLink="true">/ds/docker/2020/09/01/Docker-04-image%EC%83%9D%EC%84%B1-%EC%97%85%EB%A1%9C%EB%93%9C.html</guid>
        <description>&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://zzsza.github.io/development/2018/04/17/docker-kubernetes/&quot;&gt;Docker와 쿠버네티스의 이해&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>03: 데이터 저장 (Volume, Mount)</title>
        <link>/ds/docker/2020/09/01/Docker-03-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%80%EC%9E%A5.html</link>
        <guid isPermaLink="true">/ds/docker/2020/09/01/Docker-03-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A0%80%EC%9E%A5.html</guid>
        <description>&lt;p&gt;&lt;img src=&quot;https://docs.docker.com/storage/images/types-of-mounts-volume.png&quot; alt=&quot;Volume과 Mount&quot; class=&quot;center&quot; /&gt;&lt;em&gt;Volume과 Mount&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Docker Conatiner에 쓰여진 데이터는 컨테이너가 삭제될 때 함께 사라진다. 하지만 이에 관계없이 우리는 데이터를 영속적으로 저장할 필요가 있다. 또한 여러개의 컨테이너를 생성하여 사용할 경우, 하나의 폴더를 공유해야 하는 일이 빈번하다.&lt;/p&gt;

&lt;p&gt;이러한 필요성에 대해 Docker는 두가지 옵션을 제공한다. 첫째가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Volume&lt;/code&gt;, 둘째가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Mount&lt;/code&gt;이다.&lt;/p&gt;

&lt;h1 id=&quot;volume&quot;&gt;Volume&lt;/h1&gt;

&lt;p&gt;이 방법은 Docker에서 권장하는 방법이다.&lt;/p&gt;

&lt;h2 id=&quot;volume의-생성&quot;&gt;Volume의 생성&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker volume create hello
hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;volume의-조회&quot;&gt;Volume의 조회&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker volume &lt;span class=&quot;nb&quot;&gt;ls
&lt;/span&gt;DRIVER              VOLUME NAME
&lt;span class=&quot;nb&quot;&gt;local               &lt;/span&gt;hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker volume inspect hello
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s2&quot;&gt;&quot;CreatedAt&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2020-05-09T17:03:46Z&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;Driver&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;local&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;Labels&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;Mountpoint&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/docker/volumes/our-vol/_data&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;our-vol&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;Options&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;Scope&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;local&quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Mountpoint&lt;/code&gt;를 보면 해당 볼륨이 어디에 있는지 알 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;볼륨을-컨테이너에-마운트하기&quot;&gt;볼륨을 컨테이너에 마운트하기&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker run &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; hello:/home/app &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; one hugojuhel/notebook &lt;span class=&quot;nb&quot;&gt;touch&lt;/span&gt; /app/test.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker run -v &amp;lt;볼륨 이름&amp;gt;:&amp;lt;컨테이너 내의 절대 경로&amp;gt; --name &amp;lt;컨테이너 이름&amp;gt; &amp;lt;image 이름&amp;gt; &amp;lt;명령&amp;gt; &amp;lt;파라미터&amp;gt;&lt;/code&gt; 형식으로 구성되어 있다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker inspect hello
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;...생략...&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;Mounts&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;volume&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;our-vol&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Source&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/docker/volumes/our-vol/_data&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Destination&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/app&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Driver&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;local&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Mode&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;z&quot;&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;RW&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
            &lt;span class=&quot;s2&quot;&gt;&quot;Propagation&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;...생략...&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제로 생성된 컨테이너를 조사하면 다음과 같이 뜨며, Type이 volume으로 지정된 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이러한 방법은 다른 컨테이너에 마운트할 때에도 동일하게 적용된다.&lt;/p&gt;

&lt;h2 id=&quot;volume-삭제&quot;&gt;Volume 삭제&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker volume &lt;span class=&quot;nb&quot;&gt;rm &lt;/span&gt;hello
Error response from daemon: remove hello: volume is &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;use - &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;f73130c9dad14644ac46b89fe4018e561a7bcbfa4118d637949642d0d5d742e4, 666dda54f6be8ca852f3150b9741a9cab5a4659fa2e83fe6ca339550072c861ex]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;삭제할 때는 mount 된 컨테이너를 모두 삭제한 뒤에야 삭제가 가능하다.&lt;/p&gt;

&lt;p&gt;삭제를 수행했다면 에러가 뜨지 않을 것이다.&lt;/p&gt;

&lt;h2 id=&quot;volume-청소&quot;&gt;Volume 청소&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker volume prune
WARNING! This will remove all &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;volumes not used by at least one container.
Are you sure you want to &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;? &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;y/N] y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;마운트 되지 않은 모든 볼륨을 한번에 정리할 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;bind-mount&quot;&gt;Bind-Mount&lt;/h1&gt;

&lt;p&gt;위의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Volume&lt;/code&gt; 방법을 보면, 경로를 docker가 제시한 경로에 맞춰서 생성된다. 하지만 시스템의 특정 경로를 기반으로 작업하고 싶은 경우도 많다. 이런 필요성에 대해 docker는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bind-Mount&lt;/code&gt;를 제공한다.&lt;/p&gt;

&lt;p&gt;사용법은 매우 간단하다. 위의 Volume 명이 들어가는 자리에, 원하는 호스트 경로를 적어주는 것으로 끝난다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; jpt &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; /Users/Choiwansik/Documents/internship/image_processing/share:/home/jovyan/share &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 28888:8888 hugojuhel/notebook /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 때 역시나 container의 절대 경로를 써주어야 한다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Mounts&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bind&quot;&lt;/span&gt;,
                &lt;span class=&quot;s2&quot;&gt;&quot;Source&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/Users/Choiwansik/Documents/internship/image_processing/share&quot;&lt;/span&gt;,
                &lt;span class=&quot;s2&quot;&gt;&quot;Destination&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/home/jovyan/share&quot;&lt;/span&gt;,
                &lt;span class=&quot;s2&quot;&gt;&quot;Mode&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;,
                &lt;span class=&quot;s2&quot;&gt;&quot;RW&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
                &lt;span class=&quot;s2&quot;&gt;&quot;Propagation&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;rprivate&quot;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Type&lt;/code&gt;이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bind&lt;/code&gt;로 묶여있음을 확인할 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;volume-vs-bind-mount&quot;&gt;Volume vs Bind-Mount&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;경로(Mount Point) 관리해 줄까? 말까?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;둘의 가장 큰 차이점은, docker가 mount point를 관리해 주느냐의 여부로 나뉜다. 그냥 막 사용하고 싶은 경우애는 volume이 맞을 수 있지만, 컨테이너화된 개발 환경을 구축하고 싶을 때는 bind-mount가 더 유리하다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.daleseo.com/docker-volumes-bind-mounts/&quot;&gt;Docker 컨테이너에 데이터 저장 (볼륨/바인드 마운트)&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>02: 명령어 모음</title>
        <link>/ds/docker/2020/09/01/Docker-02-%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C.html</link>
        <guid isPermaLink="true">/ds/docker/2020/09/01/Docker-02-%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C.html</guid>
        <description>&lt;h2 id=&quot;설치&quot;&gt;설치&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/editions/community/docker-ce-desktop-mac&quot;&gt;mac 용 도커&lt;/a&gt; 설치하기&lt;/p&gt;

&lt;h2 id=&quot;docker-image-download&quot;&gt;Docker image download&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull hugojuhel/notebook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hub.docker.com/&quot;&gt;Docker Hub&lt;/a&gt; 에서 원하는 docker 이미지를 다운로드&lt;/li&gt;
  &lt;li&gt;혹은 아래 예제와 같이 명령어로 다운받을 수도 있음&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hub.docker.com/r/hugojuhel/notebook&quot;&gt;사용한 이미지&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;docker-image-확인&quot;&gt;Docker image 확인&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;설치한 이미지들을 볼 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;docker-container-생성-및-실행&quot;&gt;Docker container 생성 및 실행&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; jpt &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; /Users/Choiwansik/Documents/internship/image_processing/share:/home/jovyan/share &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; 28888:8888 hugojuhel/notebook /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8IxbK%2FbtquUAR4pmA%2FoIzcYiAR8kkDunLCKSWwT1%2Fimg.png&quot; alt=&quot;도커 명령어 설명&quot; /&gt;&lt;em&gt;사용자 상황에 맞게 옵션 골라 사용&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;명령어는 항상 root 권한으로 실행한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-i(interactive)&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-t(Pseudo-try)&lt;/code&gt; 옵션 : 실행된 Bash 셸에 입력 및 출력을 할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-v&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--volume&lt;/code&gt; 옵션 : host folder와 공유할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;jupyter-notebook-실행&quot;&gt;jupyter notebook 실행&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook &lt;span class=&quot;nt&quot;&gt;--ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.0.0.0 &lt;span class=&quot;nt&quot;&gt;--allow-root&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행하게 되면, 아까 연결해 두었던 로컬 포트로 접속할 경우 사용할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;docker-명령어&quot;&gt;Docker 명령어&lt;/h2&gt;

&lt;p&gt;도커 명령어 Cheat Cheet이다. 나중에 이거만 보고 사용하도록 하자.&lt;/p&gt;

&lt;h4 id=&quot;프로세스-보기&quot;&gt;프로세스 보기&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker ps &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;-a 옵션을 사용하면 정지된 컨테이너까지 모두 출력하고, 옵션을 사용하지 않으면 실행되고 있는 컨테이너만 출력한다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-시작하기&quot;&gt;컨테이너 시작하기&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker container start hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이름 대신 container_id를 사용해도 된다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-재부팅&quot;&gt;컨테이너 재부팅&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker container restart hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;운영체제 재부팅과 유사하다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-접속하기&quot;&gt;컨테이너 접속하기&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker container attach hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;bash에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;exit&lt;/code&gt; 혹은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ctrl+D&lt;/code&gt; 를 입력하면 컨테이너가 정지된다.&lt;/p&gt;

&lt;h4 id=&quot;exec-명령으로-컨테이너-외부에서-명령-실행하기&quot;&gt;exec 명령으로 컨테이너 외부에서 명령 실행하기&lt;/h4&gt;

&lt;p&gt;현재 hello 컨테이너의 bin/bash를 실행한 상태라고 가정하자. 그리고 해당 컨테이너에 접속하지 않은 상태로, hello 컨테이너 안의 명령을 실행해보자.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker container &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;hello &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hello World&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker container exec &amp;lt;컨테이너 이름&amp;gt; &amp;lt;명령&amp;gt; &amp;lt;매개변수&amp;gt;&lt;/code&gt; 형식이다. 컨테이너 대신 컨테이너 id를 사용할 수 있다. 이 명령어는 컨테이너가 실행되고 있는 상태에서만 사용할 수 있으며 정지된 상태에서는 사용할 수 없다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker exec&lt;/code&gt; 명령은 이미 실행된 컨테이너에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apt-get, yum&lt;/code&gt; 과 같은 명령으로 패키지를 설치하거나 각종 데몬을 실행할 때 활용할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-정지하기&quot;&gt;컨테이너 정지하기&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker container stop hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정지한 경우 다시 attach하고 싶으면 start후 가능하다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-삭제하기&quot;&gt;컨테이너 삭제하기&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker container &lt;span class=&quot;nb&quot;&gt;rm &lt;/span&gt;hello
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;container 명령어를 쓰지 않아도되지만 최신 버전에서는 권장한다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-실행-상태로-빠져나오기&quot;&gt;컨테이너 실행 상태로 빠져나오기&lt;/h4&gt;

&lt;p&gt;컨테이너 안에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl+pq&lt;/code&gt;을 누르면 된다.&lt;/p&gt;

&lt;h4 id=&quot;컨테이너-내-사용자-비밀번호를-모를-때&quot;&gt;컨테이너 내 사용자 비밀번호를 모를 때&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker container &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; 0 &lt;span class=&quot;nt&quot;&gt;-it&lt;/span&gt; jpt /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-u&lt;/code&gt;는 default user라 password를 필요로 하지 않는다.&lt;/p&gt;

&lt;h4 id=&quot;이미지-삭제하기&quot;&gt;이미지 삭제하기&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker rmi ubuntu:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker rmi &amp;lt;이미지 이름&amp;gt;:&amp;lt;태그&amp;gt;&lt;/code&gt; 형식이다. 이미지 이름 대신 id를 사용해도 된다. 태그를 주는 이유는 같은 이름 인 경우 모두 삭제되기 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;정리&quot;&gt;정리&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;명령&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Code&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;버전 확인&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker -v&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;이미지 다운로드&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker pull [이미지 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;다운로드된 이미지 목록&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker images&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 생성&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker create [옵션] [이미지 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 생성 및 실행&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker run [옵션] [이미지 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 실행&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker start [컨테이너 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 재실행&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker restart [컨테이너 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 접속&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker attach [컨테이너 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 정지&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker stop [컨테이너 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;실행중인 컨테이너 목록&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker ps&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;정지된 컨테이너 목록&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker ps -a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 명 변경&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker rename [기존 컨테이너 명] [새로운 컨테이너 명]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;컨테이너 삭제&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ docker rm [컨테이너 명]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://pbj0812.tistory.com/134&quot;&gt;[Docker] 설치, 다운로드, 실행, jupyter notebook 연동, 삭제, 기타 등등&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;pre.highlight margin-top 1em
ul margin-bottom 0
p margin-bottm 1em
p margin-top 1em&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>01: 개요</title>
        <link>/ds/docker/2020/09/01/Docker-01-%EA%B0%9C%EC%9A%94.html</link>
        <guid isPermaLink="true">/ds/docker/2020/09/01/Docker-01-%EA%B0%9C%EC%9A%94.html</guid>
        <description>&lt;p&gt;&lt;img src=&quot;https://subicura.com/assets/article_images/2017-01-19-docker-guide-for-beginners-1/docker-works.png&quot; alt=&quot;도커란?&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;도커란? (되게 귀엽다)&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;개념&quot;&gt;개념&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;개발자와 시스템 관리자가 컨테이너 기술을 사용하여 어플리케이션을 개발, 배포, 실행하기 위한 플랫폼&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;컨테이너 기술을 리눅스에서 사용되던 기술이다. 이 때, 이 기술을 사용하여 응용프로그램을 배포하는 것을 컨테이화 시킨 것이다. 새로운 기술은 아니지만, 이를 통해 매우 편리하고 간편하게 배포하는 것이 가능하다.&lt;/p&gt;

&lt;p&gt;컨테이너 기술은 아래와 같은 특징들이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;유연성 (Flexible) : 복잡한 어플리케이션들도 모두 컨테이너화 할 수 있다.&lt;/li&gt;
  &lt;li&gt;경량화 (Lightweight) : 컨테이너는 호스트 커널을 활용하고 공유한다.&lt;/li&gt;
  &lt;li&gt;변화 관리 편의성 (InterChangeable) : 업데이트 및 업그레이드를 즉시 배포할 수 있다.&lt;/li&gt;
  &lt;li&gt;포터블 (Portable) : 로컬로 구축하고, 클라우드와 가상화에 배치가 가능하고, 어디서나 실행할 수 있다.&lt;/li&gt;
  &lt;li&gt;확장성 (Scalable) : 컨테이너 복제본을 늘리고 자동 배포가 가능하다.&lt;/li&gt;
  &lt;li&gt;스택화 (Stackable) : 서비스들에 대한 수직적 또는 수평적 디자인이 매우 용이하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://i1.wp.com/www.docker.com/blog/wp-content/uploads/2020/07/Mainstream-and-Growing.png?resize=1110%2C740&amp;amp;ssl=1&quot; alt=&quot;Docker 사용량&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;어마무시한 도커 사용량&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;이미지와-컨테이너&quot;&gt;이미지와 컨테이너&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://www.docker.com/sites/default/files/social/docker_facebook_share.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;40%&quot; /&gt;&lt;em&gt;docker contatiner&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이미지
    &lt;ul&gt;
      &lt;li&gt;코드, 런타임, 라이브러리, 환경 변수 및 구성 파일 등 응용프로그램을 실행하는 데 필요한 모든 것을 포함하는 실행가능 패키지&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;컨테이너
    &lt;ul&gt;
      &lt;li&gt;이미지의 런타임 인스턴스&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 두개의 개념은 도커를 이해하는 데 매우 중요하다. class는 instance의 설계도이다. 마찬가지로 이 class에 해당하는 것이 바로 image이며, 이를 메모리단에 올린 것을 container라 한다.&lt;/p&gt;

&lt;h2 id=&quot;컨테이너의-동작-방식&quot;&gt;컨테이너의 동작 방식&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://subicura.com/assets/article_images/2017-01-19-docker-guide-for-beginners-1/vm-vs-docker.png&quot; alt=&quot;&quot; class=&quot;center&quot; width=&quot;80%&quot; /&gt;&lt;em&gt;가상 머신과 도커의 차이점&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;기존에 사용하던 가상 머신은, Host OS위에 Guest OS를 얹어 사용하는 방식이다. 사용법은 간단하지만 &lt;strong&gt;느리다&lt;/strong&gt;라는 치명적인 단점을 갖고 있다.
이러한 상황을 개선하기 위해 CPU 가상화 기술을 사용한 KVM(Kernel-based Virtual Machine)이 등장했다. 하지만 여전히 성능 문제가 있었다. 이를 해결한 것이 Docker contatiner이다. 이는 바로 Host OS위에서 격리만하여 프로세스를 처리하는 방식이다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://subicura.com/2017/01/19/docker-guide-for-beginners-1.html&quot;&gt;초보를 위한 도커 안내서 - 도커란 무엇인가?&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>Updater 영상 처리 intern</title>
        <link>/cv/internship/2020/09/01/Updater-%EC%98%81%EC%83%81%EC%B2%98%EB%A6%AC-%EC%9D%B8%ED%84%B4.html</link>
        <guid isPermaLink="true">/cv/internship/2020/09/01/Updater-%EC%98%81%EC%83%81%EC%B2%98%EB%A6%AC-%EC%9D%B8%ED%84%B4.html</guid>
        <description>&lt;p&gt;기간 : 0901~1031&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>03 : deckgl</title>
        <link>/ds/ml/2020/08/24/%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-02-%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-03-deckgl.html</link>
        <guid isPermaLink="true">/ds/ml/2020/08/24/%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-02-%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-03-deckgl.html</guid>
        <description>&lt;p&gt;공간 데이터를 시각화 할 수 있는 deckgl에 대해 알아본다.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Aug 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>02 : folium</title>
        <link>/ds/ml/2020/08/24/%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-02-%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-02-folium.html</link>
        <guid isPermaLink="true">/ds/ml/2020/08/24/%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-02-%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-02-folium.html</guid>
        <description>&lt;p&gt;공간 데이터를 시각화 할 수 있는 folium에 대해 알아본다.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Aug 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>01 : geopandas</title>
        <link>/ds/ml/2020/08/24/%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-01-geopandas.html</link>
        <guid isPermaLink="true">/ds/ml/2020/08/24/%EA%B3%B5%EA%B0%84%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-01-geopandas.html</guid>
        <description>&lt;p&gt;공간 데이터를 다룰 수 있게 하는 패키지 geopandas에 대해 알아본다.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Aug 2020 00:00:00 +0900</pubDate>
      </item>
    
      <item>
        <title>항공 지연 예측 프로젝트</title>
        <link>/cv/projects/2020/08/01/%ED%95%AD%EA%B3%B5-%EC%A7%80%EC%97%B0-%EC%98%88%EC%B8%A1-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8.html</link>
        <guid isPermaLink="true">/cv/projects/2020/08/01/%ED%95%AD%EA%B3%B5-%EC%A7%80%EC%97%B0-%EC%98%88%EC%B8%A1-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8.html</guid>
        <description>
</description>
        <pubDate>Sat, 01 Aug 2020 00:00:00 +0900</pubDate>
      </item>
    
  </channel>
</rss>
