---
layout: post
title: "01: 빅데이터의 이해"
category: "DS/ML"
comments: true
tags: [Data Science, "Machine Learning", "빅데이터분석기사"]
feature-img: "assets/img/77.jpg"
feature-title: ""
use_math: true
summary: "개요 및 활용, 기술과 제도에 대해 간략히 알아보자."
series: "빅데이터분석기사 - 필기"
---

# 빅데이터 특징

* 정형 + 비정형
* 데이터로부터 가치 추출, 결과 분석
* 가치 추출 방법 : DIKW 피라미드

## DIKW 피라미드

* 데이터
  * 객관적 사실, 순수한 상태
* 정보
  * 데이터를 가공 처리
  * 의미 도출
* 지식
  * 정보를 구조화
* 지혜
  * 지식을 기반으로 판단


## 데이터 크기

K -> M -> G -> T -> P -> E -> Z -> Y

(뒤에 EZY)


## 빅데이터 특징

bold체는 3V

1. **Volume(크기)**
   * 크기는 상식적으로 중요함
2. **Variety(다양성)**
   * 정형, 비정형
3. **Velocity(속도)**
   * 정보의 생성 속도 가속화, 처리 속도 역시 중요
4. Veracity(신뢰성)
   * 데이터 양이 증가하기 때문에 품질 자체가 중요해짐
5. Value(가치)
   * 유용한 것을 얻을 수 있는가?
6. Validity(정확성)
   * 정확한 분석
7. Volatility(휘발성)
   * 데이터가 의가 있는 기간

## 빅데이터의 유형

* 정형
  * 정형화된 스키마 구조
  * RDBMS
  * SQL
* 비정형
  * 구조화되어 있으나 메타데이터나 스키마정보를 포함하는 데이터.
  * 구조화되어 있지만 추가적인 정보가 들어가는 경우
  * XML
  * HTML
  * JSON
* 비정형
  * 각각이 데이터 객체로 구분된 경우
  * 이미지
  * 음성
  * 동영상
  * 텍스트


## 데이터 지식 경영

* 암묵지
  * 내면화(자기만 알고 있는 경험등)
  * 공통화
  * 수영, 태권도
* 형식지
  * 표출화(문서를 공유함)
  * 연결화
  * 메뉴얼

# 빅데이터의 가치

* 경제적 자산 - 새로운 기회 창출
* 불확실성 제거 - 미래 예측(시뮬레이션)
* 리스크 감소 - 미래 예측을 통해 위험 감소
* 스마트한 경쟁력 - 지능화 서비스
* 타 분화 융합 - 새로운 가치 창출

## 가치 산정의 어려움

* 데이터 활용 방식의 다양화
* 새로운 가치 창출 - 없던 가치를 만듦
* 분석 기술의 급속한 발전


## 빅데이터 영향

* 기업
  * 혁신 수단 제공
  * 경쟁력 강화
  * 생산성 향상
* 정부
  * 환경 탐색
  * 상황 분석
  * 미래 대응
* 개인
  * 목적에 따른 활용

## 빅데이터 위기 요인

* 사생활 침해 - SNS보고 도둑 듦
* 책임 원칙 훼손 - 아직 안했는데 범죄자 취급
* 데이터 오용 - 데이터 기반으로 예측하기 때문에 언제나 맞을 수 없음

## 빅데이터 통제 방안

* 알고리즘 접근 허용 - 알고리즈미스트(피해 구제 전문 인력)
* 책임 강조 - 정보 사용시 책임을 지는 방안
* 결과 기반 책임 적용 - 결과를 바탕으로 책임진다.



# 빅데이터 산업 이해
* 스마트폰, SNS, IoT 확산으로 인해 데이터 활용 증가
* **클라우드 컴퓨팅** 기술 발전 때문에, 처리 비용이 감소, 결과적으로 발전중


# 빅데이터 조직 설계

## 빅데이터 업무 프로세스

* 도입
  * 도입 기획
  * 기술 검토
  * 조직 구성
  * 예산 확보
* 구축
  * 요구사항 분석
  * 설계
  * 구현
  * 테스트
* 운영
  * 운영 계획 수립

## 조직 설계 절차

1. 경영 전략 및 사업 전략 수립
2. 전체 조직 구조 설계
3. 핵심 업무 프로세스 검토
4. 팀 조직 구조 설계
5. 핵심 인력 선발
6. 역할과 책임 할당
7. 성과 측정 기준 수립
8. 역량 교육 및 훈련

본질은 다음과 같다. 

1. 무엇을 하고 싶은가?
2. 어떻게 할 것인가?
   1. 전체 구조는?
   2. 그 구조에서 맡는 업무는?
   3. 해당 팀의 구조는?
   4. 거기에 맞는 인력은?
   5. 그 인력의 업무 범위는? 책임은?
   6. 측정 방법은?
   7. 능력이 없다면 교육은?

## 조직 구조 설계의 요소

* 업무 활동
  * 수직 업무 활동
    * 경영 계획, 예산 할당 등 우선순위 결정 : 대장이 결정해서 일을 던져줌
  * 수평 업무 활동
    * 업무 프로세스 절차별로 업무 배분 : 팀이 받아서 분산 작업함
* 부서화
  * 조직의 미션과 목적을 달성하기 위한 구조를 만든다.
  * 집중, 기능, 분산으로 나뉜다.
* 보고 체계

### 조직 구조 유형

![image](https://user-images.githubusercontent.com/37871541/114683896-6060d980-9d4b-11eb-8d31-f88ac0106be6.png){: .center-verysmall }_조직 구조 유형_


* 집중 구조
    * 분석 전담 조직을 만듦
    * 그 조직에서 일을 받고 우선순위 알아서 정함
    * 다른 부서에서 일을 던졌는데 알고보니 일이 중복될 경우가 발생할 수 있음
* 기능 구조
  * 각각의 부서에다가 분석가(기능)를 하나씩 둚
  * 전체적으로 요인을 분석하기가 어려움
* 분산 구조
  * 집중 구조와 기능 구조를 합한 경우
  * 일단 부서를 떼되, 인력을 각 부서에 배치함
  * 전체적으로 우선 순위를 정할 수 있음
  * 중앙에서 통제하기 때문에 가장 좋은 방법을 공유할 수 있음


## 조직 역량

* Soft Skill
  * 통찰력 - 호기심, 비판 능력
  * 협업 능력 - 커뮤니케이션
  * 전달력 - 스토리 텔링, 시각화
* Hard Skill
  * 이론적 지식
  * 분석 기술 숙련도

* 직무별 역량 개발 절차 - 특정 조직에 필요한 역량 알아내기
  * 미션/목표 검토 - 뭐하는 조직이지?
  * 구성원의 행동 특성 도출 - 잘하는 녀석들의 행동 관찰
  * 구성원의 역량 도출 - 관찰 내용을 기반으로 역량 뽑기
  * 역량 모델 확정 - 이 역량을 검토하고 확정하여 해당 직무의 역량을 고정함.


* 역량 교육 체계 설계 - 정해진 역량을 어떻게 교육시키냐.
  * 요구사항 분석
  * 역량 모델 검토
  * 역량 차이 분석
  * 역량 매트릭스 작성
  * 직무별 교육체계 설계





# 빅데이터 기술 및 제도

## 빅데이터 플랫폼

수집 -> 저장 -> 분석 -> 활용

1. 수집
   * ETL
   * 크롤러
2. 저장
   * RDBMS
   * NoSQL
3. 분석
   * SNS 분석
   * 텍스트 분석
   * 통계
4. 활용
   * 히스토그램
   * 인포그래픽
   * 시각화


### 데이터 형식

* HTML
* XML
* CSV - `,`
* JSON - key-value


### 플랫폼 구축 소프트웨어

* R - 분석 프로그래밍 언어
* Oozie - 워크플로우 관리
  * 하둡 작업 관리 워크플로우
* Flume - 데이터 수집
  * 로그 데이터 수집
* HBase - 분산 데이터베이스
  * HDFS 제공
* Sqoop - **정형** 데이터 수집
  * SQL to Hadoop 약자
  * RDBMS -> HDFS로 보냄
  * 혹은 반대 방향

### 분산 컴퓨팅 환경 소프트웨어
* Map Reduce
  * key-value
  * map(데이터 취합) -> shuffle(통합 처리) -> reduce(데이터 정리)
* HDFS
  * Hadoop Distributed File System
  * 대용량 파일을 분산된 서버에 저장하고, 처리할 수 있는 파일 시스템
  * Name node, data node로 구성
* 아파치 하둡
  * HDFS + Map Reduce = 생태계
  * Spark, Hive, YARN, Cassandra, Pig
* YARN
  * 하둡의 맵리듀스 처리 부분을 새롭게 만든 **자원 관리 플랫폼**
  * Master, Slave로 구성된다.
* 아파치 스파크
  * 하둡 기반 대규모 데이터 분산 처리 시스템
  * 스트리밍 데이터, 온라인 머신러닝등 **실시간 데이터 처리**
  * scala, java, python, R


### 하둡 에코 시스템
![image](https://user-images.githubusercontent.com/37871541/114687650-efbbbc00-9d4e-11eb-9a33-a7245ad702c4.png){: .center-small }


* 비정형 데이터 수집
  * Chukwa (척와)
  * Flume - 로그 데이터
  * Scribe - 실시간 스트리밍
* 정형 데이터 수집
  * Sqoop - HDFS <-> RDBMS
  * Hiho
* 분산 데이터 저장
  * HDFS
* 분산 데이터 처리
  * Map Reduce - 키-밸류로 처리
* 분산 데이터베이스
  * HBASE


* 데이터 가공
  * Pig
  * Hive
* 데이터 마이닝
  * Mahout
* 실시간 SQL 질의
  * Impala
* 워크 플로우 관리
  * Oozie
* 분산 코디네이션
  * Zookeeper


## 개인정보보호 관련 법령

* 개인정보 보호법
* 정보통신망법
* 신용정보법
* 위치정보법
* 개인정보 안전성 확보 조치 기준

마이데이터란? - 자신의 정보 관리, 통제, 능동적 활용


## 개인정보 비식별 조치

* 가명 처리
  * 장길산, 20세, 인천 거주, 미래대 재학 -> 김식별, 20대, 인천 거주, 외국대 재학
* 총계 처리 - 통계 방법이 있어야 함
  * 장길정 160cm, 김식별 150cm -> 물리학과 학생 키 합: 310cm, 평균키 155cm
* 데이터 삭제
  * 주민등록번호 -> 몇년 생인지만 확인
* 데이터 범주화 -> 묶는 느낌이 강함
  * 장길산, 41세 -> 장 씨, 40~50세
* 데이터 마스킹 - 문자로 대체
  * 장OO 41세, OO대학

