---
layout: post
title: "04: 데이터 전처리"
category: "DS/ML"
comments: true
tags: [Data Science, "Machine Learning", "빅데이터분석기사"]
feature-img: "assets/img/77.jpg"
feature-title: ""
use_math: true
summary: 데이터 정제 방법, 변수 처리 방법에 대해 알아본다."
series: "빅데이터분석기사 - 필기"
---

# 데이터 정제

* 전처리 결과는 반드시.
* 결과에 직접적인 영향
* 반복적인 수행
* 가장 많은 시간 소요
* 정제 -> 결측값 처리 -> 이상값 처리 -> 분석 변수 처리
* 모든 데이터 대상으로 진행한다.


## 정제 방법

* 삭제
  * 문제 발생 여지 존재
* 대체
  * 평균값, 최빈값, 중앙값
  * 왜곡의 여지
* 예측값 적용
  
## 정제 기법

* 변환
  * 코드 변환(남여->M/F)
  * 형식 변환(주번)
  * 다양한 값을 일관된 형태로 변환
* 파싱
  * 규칙 분할
* 보강
  * 추가정보 반영

## 정제 기술

* ETL - 추출, 가공, 저장
* 맵 리듀스
  * 배치 형태 처리 방식으로 데이터 양이 많을 경우 느림
* Spark/Storm
  * **Inmemory 처리 방식**
  * 기계학습, 라이브러리 지원
* CEP(Complex Event Processing)
  * 이벤트 처리 결과값 수집 및 러히
  * 실시간 데이터 처리 기술
* Pig
  * 대용량 데이터 집합 분석 플랫폼
* Flume
  * 로그 데이터 수집 및 처리


# 데이터 결측값 처리

![image](https://user-images.githubusercontent.com/37871541/114720910-623e9300-9d73-11eb-9f09-20234b2719d7.png){: .center-verysmall }


* 완전 무작위 결측
  * 결측값이 아무 상관 없음
* 무작위 결측
  * 누락 자료가 특정 변수와 관련은 되어 있지만 결과는 관계가 없음
  * 남성은 설문에 기재할 확률이 낮지만 그 결과와는 상관이 없음
* 비 무작위 결측
  * 연관이 있는 경우
  * 소득에 대한 설문 시, 고소득자가 무응답률이 높은 경우

결과 자체가 응답에 영향을 주는가? 의 여부로 판단하면 된다.

* NA(Not Available) - 기록되지 않은 값
* NaN(Not a Number) - 숫자가 아닌 값
* inf - 무한대
* NULL - 값이 없음

## 단순 대치법

* 완전 대치법
* 평균 대치법
* 단순 확률 대치법
  * 핫덱 대체 - 무응답을 현재 진행 연구에서 비슷한 성향을 가진 사람으로 대체
  * 콜드덱 대체 - 외부 연구에서 있는 사람으로 대체
  * 혼합 - 평균 대치와 확률 대치 섞어
  

## 다중 대치법

* 대치
* 분석
* 결합
  


# 데이터 이상값 처리

* 데이터 입력 오류
* 측정 오류
* 실험 오류
* 고의적인 이상값
* 표본 추출 에러


## 검출 방법

![image](https://user-images.githubusercontent.com/37871541/114723917-075a6b00-9d76-11eb-984a-06e52b3d3045.png){: .center-verysmall}

* 개별 데이터 관찰
* 통계값 확인
  * ESD(Extream Studentized Deviation) - 3 표준편차 떨어진 값을 이상값으로 판단
  * 기하평균 - 기하평균으로부터 2.5표준편차 떨어진 값을 이상값으로 판단
  * 사분위 수를 이용한 방법 - Q1, Q3각각을 기준으로 (Q3-Q1)*1.5만큼 왼쪽, 오른쪽으로 떨어진 값을 이상값으로 판단 : Boxplot
  * 표준화 점수를 이용
  * 딕슨의 Q 검정 - 데이터수가 30개 미만인 경우 사용
  * 그럽스 T 검정 - 단변량 정규분포 자료에서 사용
  * 카이제곱 검정 - 데이터가 정규분포이나 수가 적은 경우 사용
* 시각화
  * 확률 밀도 함수 사용
  * 히스토그램
  * 시계열 차트
* 머신러닝 기법
  * K-means
* 마할라노비스 거리 - 분포를 고려한 거리 측도
* LOF(Local Outlier Factor) - 관측치 주변(local) 밀도와 비교하여 탐색
* iForest - Decision Tree를 이용하여 이상값 탐지



# 분석 변수 처리

* 과적합 방지
* 차원의 저주 방지
* 성능 향상

## 필터 기법

* 정보 이득
* 카이제곱 검정
* 피셔 스코어
* 상관 계수

## 래퍼 기법

* 그리디 알고리즘
* 전진 선택법
  * 하나씩 추가하는 방법
* 후진 선택법
  * 하나씩 제거하는 방법
* 단계적 방법
  * 함께 사용하는 방법

## 임베디드 기법

* Lasso - L1 norm을 추가하여 자동적으로 줄임
* Ridge - L2 norm을 추가하여 제약을 줌
* Elastic Net - 두 제약을 선형 결합하여 사용


# 차원 축소

* 분석 대상 변수의 정보를 최대한 유지하면서 변수 개수를 줄이는 방법
* y는 사용하지 않고 진행하기 때문에 비지도 학습 방법이다.
* 효과적인 시각화 가능


## 차원 축소 기법

* 주성분 분석(PCA)
  * 공분산 행렬, 상관행렬 사용
  * 정방행렬에서만 가능
* 특이값 분해(SVD)
  * M x N 차원 행렬 데이터에서 특이값 추출 후 축약
* 요인 분석(Factor Analysis)
* 독립 성분 분석(ICA)
* 다차원 척도법(MDS)


# 파생 변수 생성

* 단위 변환
* 표현 형식 변환
* 통계량 생성
* 변수 결합

# 변수 변환

* 단순 기능 변환
  * 로그, 역수, 루트, 제곱
* 비닝(Binning)
  * 데이터를 범주화함
* 정규화
  * 최소-최대 정규화, z-score
* 표준화
  * z-score


# 불균형 데이터 처리

* 언더 샘플링
  * 데이터의 소실이 크다.
* 오버 샘플링
  * 과적합을 초대할 수 있다.
  * 검증 성능은 나빠질 수 있다.
* 임곗값 이동
* 앙상블 기법


# 중위수 구하기

* n이 홀수 : $n-1 \over 2$
* n이 짝수 : $n-2\over 2$, $n \over 2$