---
layout: post
title: "07: 모델링"
category: "DS/ML"
comments: true
tags: [DS, "kaggle", "ML", "titanic", "modeling"]
feature-img: "assets/img/36.jpg"
feature-title: ""
use_math: true
series: "Titanic"
---

Kaggle에 있는 Titanic Prediction 문제의 모델링을 수행한다.


# Modeling
데이터 사이언스는 수학, CS, 산업에 대한 이해 모두가 필요한 분야이다. 그렇기 때문에 이 세 부분을 모두 주의깊게 공부할 필요가 있다. 지금 부터 할 작업은 수학적 이해가 있으면 좋지만 구현하는데에는 크게 필요가 없다. 지금은 큰 그림을 이해하는 것을 우선으로 한다.

기계학습이라는 단어 자체에는 기계에게 학습을 가르친다는 착각을 일으킬 수 있는 여지가 많다. 하지만, 실제로는 그렇지 않다. 다양한 사람들이 좋은 라이브러리를 사용하여 많은 문제를 해결할 수 있게 된 것은 좋으나, 이러한 문제 때문에 오히려 제대로 된 방법을 사용못하는 사람도 많아졌다. 데이터 과학자는 데이터라는 목재를 가지고, 목표에 대한 적절한 도구를 사용하여 문제를 해결해야 한다. 개집을 짓는다면 그에 맞는 적절한 도구로 충분하지만, 큰 목조 건물을 짓는다면, 더 효율적인 도구를 통하여 문제를 해결해야 할 것이다. 결과적으로 알고리즘에 대한 정확한 이해도와 그를 사용할 수 있는 능력을 키워야 할 것이다.

기계학습의 목적은, 인간의 문제를 해결하는 것이다. 이 방법으로는 크게 지도학습, 비지도 학습, 강화 학습으로 구분된다. 지도학습은 정답을 포함한 데이터 세트를 가지고 분류하는 것, 비지도 학습은 정답이 없는 데이터 세트를 가지고 모델을 학습하는 것이다. 강화학습은 두 학습의 하이브리드 방식으로 볼 수 있다.

타이타닉 문제는 연속적인 값을 예측하는 것이 아닌, 이진 분류 문제이다. 따라서 지금부터 sklearn 라이브러리의 분류 알고리즘을 사용하여 분석을 시작한다.

![sklearn Mindmap](https://scikit-learn.org/stable/_static/ml_map.png){: .center}

[Sklearn Estimator Overview](http://scikit-learn.org/stable/user_guide.html)  
[Sklearn Estimator Detail](http://scikit-learn.org/stable/modules/classes.html)  
[Choosing Estimator Mind Map](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)  
[Choosing Estimator Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf)  


지도 학습 중, 분류 문제에 대한 알고리즘에 대해 알아보자.

**Machine Learning Classification Algorithms:**  
[Ensemble Methods](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)  
[Generalized Linear Models (GLM)](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)  
[Naive Bayes](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes)  
[Nearest Neighbors](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors)  
[Support Vector Machines (SVM)](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm)  
[Decision Trees](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree)  
[Discriminant Analysis](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.discriminant_analysis)  


## 기계학습 알고리즘을 고르는 방법
> 최고의 알고리즘은 없다. NFLT (No Free Lunch Theorem)

최고의 알고리즘은 존재하지 않는다. 다양한 알고리즘을 통해 검증하여 최고의 답안을 내는 것이 최선이다.


## 머신 러닝 알고리즘 선택 및 초기화
```python
# Machine Learning Algorithm
MLA = [
    #Ensemble Methods
    ensemble.AdaBoostClassifier(),
    ensemble.BaggingClassifier(),
    ensemble.ExtraTreesClassifier(),
    ensemble.GradientBoostingClassifier(),
    ensemble.RandomForestClassifier(),

    #Gaussian Processes
    gaussian_process.GaussianProcessClassifier(),
    
    #GLM (Generalized Linear Model)
    linear_model.LogisticRegressionCV(),
    linear_model.PassiveAggressiveClassifier(),
    linear_model.RidgeClassifierCV(),
    linear_model.SGDClassifier(),
    linear_model.Perceptron(),
    
    #Navies Bayes
    naive_bayes.BernoulliNB(),
    naive_bayes.GaussianNB(),
    
    #Nearest Neighbor
    neighbors.KNeighborsClassifier(),
    
    #SVM
    svm.SVC(probability=True),
    svm.NuSVC(probability=True),
    svm.LinearSVC(),
    
    #Trees    
    tree.DecisionTreeClassifier(),
    tree.ExtraTreeClassifier(),
    
    #Discriminant Analysis (판별 분석)
    discriminant_analysis.LinearDiscriminantAnalysis(),
    discriminant_analysis.QuadraticDiscriminantAnalysis(),

    
    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html
    XGBClassifier()    
    ]



#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit
#note: this is an alternative to train_test_split
cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # 60/30 으로 나눈다. 10%는 일부러 둔다. 그 작업을 10번 만든다.

# 알고리즘을 비교하기 위한 표를 만든다.
MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']
MLA_compare = pd.DataFrame(columns = MLA_columns)

# 각각의 알고리즘이 예측한 값을 보여줄 테이블을 만든다.
MLA_predict = data1[Target]

# row 하나에 하나의 알고리즘에 대한 결과를 적을 것이므로, row_index를 변수로 잡아준다.
row_index = 0
for alg in MLA:

    #set name and parameters
    MLA_name = alg.__class__.__name__
    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name
    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())
    
    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate
    # 만들어진 10개의 split set에 대해 검증을 한다. 이 작업 이후에 결과는 10개가 나올 것이다.
    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv  = cv_split)

    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()
    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() # 10개의 결과에 대해 평균치
    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   
    # https://ko.wikipedia.org/wiki/68-95-99.7_규칙
    # 제대로 된 random으로 sampling을 했다면, cross-validation으로 나온 결과는 3시그마 규칙을 만족할 것이다.(즉, 정규 분포로 나왔을 것이다.)
    # 이 값을 얻는 이유는, 최악의 훈련 결과를 알아보기 위함이다. 편차가 작을 수록 일반화된 모델이라는 생각을 할 수 있다.
    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!
    

    #save MLA predictions - see section 6 for usage
    alg.fit(data1[data1_x_bin], data1[Target])
    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])
    
    row_index+=1

    
#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html
# test 정확도가 높은 순서대로 sorting한다.
MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)
MLA_compare
```
![image](https://user-images.githubusercontent.com/37871541/81290326-d6bc7c80-90a2-11ea-9e43-7e898b23d80c.png){: .center}


```python
MLA_predict.sample(10)
```

![image](https://user-images.githubusercontent.com/37871541/81290468-171bfa80-90a3-11ea-9eee-35456da7b01c.png){: .center}



```python
#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html
sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')

#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html
plt.title('Machine Learning Algorithm Accuracy Score \n')
plt.xlabel('Accuracy Score (%)')
plt.ylabel('Algorithm')
```

![Unknown-12](https://user-images.githubusercontent.com/37871541/81290877-c22cb400-90a3-11ea-92e6-01e0ada98c7c.png){: .center}










### Reference
[kaggle Notebook](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy#)  